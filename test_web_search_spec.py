"""
OpenAI Responses API Webæ¤œç´¢æ©Ÿèƒ½ æ­£å¼ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
è¦ä»¶å®šç¾©æ›¸ï¼ˆtemp_layout.mdï¼‰ã«åŸºã¥ãå®Ÿè£…

æ¤œè¨¼é …ç›®:
1. Webæ¤œç´¢ã®å®Ÿè¡Œ
2. å¼•ç”¨æƒ…å ±ï¼ˆannotationsï¼‰ã®å–ã‚Šå‡ºã—
"""

import asyncio
import sys
import os
import time
import json
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass

from dotenv import load_dotenv

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from openai import OpenAI
    # Responses APIã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª
    client_test = OpenAI(api_key="test")
    if not hasattr(client_test, 'responses'):
        print("âŒ Error: ã“ã®OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯Responses APIã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“")
        print("ãƒ™ãƒ¼ã‚¿APIã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        sys.exit(1)
except ImportError:
    print("âŒ Error: OpenAI library not installed. Run: pip install openai")
    sys.exit(1)


@dataclass
class TestResult:
    """ãƒ†ã‚¹ãƒˆçµæœã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿"""
    test_name: str
    status: str  # PASS | FAIL
    details: Dict[str, Any]
    errors: List[str]


class WebSearchTestClient:
    """Webæ¤œç´¢ãƒ†ã‚¹ãƒˆå°‚ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key)
        self.model = "gpt-5.2"  # è¦ä»¶å®šç¾©æ›¸ã«åŸºã¥ããƒ¢ãƒ‡ãƒ«
    
    def text(self, role: str, content: str) -> Dict[str, Any]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ç”¨ã®Response API input itemã‚’ä½œæˆ
        
        Args:
            role: "system", "user", "assistant"ã®ã„ãšã‚Œã‹
            content: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
            
        Returns:
            Response APIç”¨ã®input item
        """
        return {
            "role": role,
            "content": [{"type": "input_text", "text": content}]
        }
    
    def generate_response_with_WebSearch(self, input_items: List[Dict[str, Any]]) -> str:
        """
        WebSearchæ©Ÿèƒ½ä»˜ããƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
        
        Args:
            input_items: Response APIå½¢å¼ã®input items
            
        Returns:
            WebSearchçµæœã‚’å«ã‚€LLMã‹ã‚‰ã®å¿œç­”
        """
        resp = self.client.responses.create(
            model=self.model,
            input=input_items,
            tools=[{"type": "web_search"}],
            store=True,
        )
        return resp.output_text
    
    def execute_web_search_with_response(self, query: str) -> Any:
        """Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã€å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™"""
        input_items = [self.text("user", query)]
        
        response = self.client.responses.create(
            model=self.model,
            input=input_items,
            tools=[{"type": "web_search"}],
            store=True,
        )
        return response

class CitationExtractor:
    @staticmethod
    def extract_citations(response: Any) -> List[Dict[str, Any]]:
        citations: List[Dict[str, Any]] = []
        seen = set()  # é‡è¤‡æ’é™¤ã—ãŸã„å ´åˆã ã‘ï¼ˆä¸è¦ãªã‚‰æ¶ˆã—ã¦OKï¼‰

        for item in getattr(response, "output", []) or []:
            if getattr(item, "type", None) != "message":
                continue

            for c in getattr(item, "content", []) or []:
                if getattr(c, "type", None) != "output_text":
                    continue

                text = getattr(c, "text", "") or ""
                for ann in getattr(c, "annotations", []) or []:
                    if getattr(ann, "type", None) != "url_citation":
                        continue

                    url = getattr(ann, "url", "") or ""
                    title = getattr(ann, "title", "") or ""
                    start = getattr(ann, "start_index", -1)
                    end = getattr(ann, "end_index", -1)

                    key = (url, start, end)
                    if key in seen:
                        continue
                    seen.add(key)

                    snippet = ""
                    if (
                        isinstance(start, int) and isinstance(end, int)
                        and 0 <= start < end <= len(text)
                    ):
                        snippet = text[start:end]

                    citations.append({
                        "url": url,
                        "title": title,
                        "start_index": start,
                        "end_index": end,
                        "text_snippet": snippet,
                    })

        return citations
    
    @staticmethod
    def _extract_from_content_item(content_item) -> List[Dict]:
        """å˜ä¸€ã®contentã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰å¼•ç”¨ã‚’æŠ½å‡º"""
        citations = []
        
        if hasattr(content_item, 'annotations'):
            citations.extend(CitationExtractor._extract_from_annotations(content_item.annotations))
        
        # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸå¼•ç”¨æƒ…å ±ã‚‚ãƒã‚§ãƒƒã‚¯
        if hasattr(content_item, 'text'):
            # ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ã‚’è§£æ
            import re
            link_pattern = r'\[([^\]]+)\]\(([^\)]+)\)'
            matches = re.findall(link_pattern, content_item.text)
            
            for title, url in matches:
                if url.startswith('http'):
                    citations.append({
                        "url": url,
                        "title": title,
                        "start_index": -1,  # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®å ´åˆã¯æ­£ç¢ºãªä½ç½®ã¯å–å¾—å›°é›£
                        "end_index": -1,
                        "source": "markdown_link"
                    })
        
        return citations
    
    @staticmethod
    def _extract_from_annotations(annotations) -> List[Dict]:
        """annotationsé…åˆ—ã‹ã‚‰å¼•ç”¨æƒ…å ±ã‚’æŠ½å‡º"""
        citations = []
        
        try:
            for annotation in annotations:
                if hasattr(annotation, 'type') and annotation.type == "url_citation":
                    citation = {
                        "url": getattr(annotation, 'url', ''),
                        "title": getattr(annotation, 'title', ''),
                        "start_index": getattr(annotation, 'start_index', -1),
                        "end_index": getattr(annotation, 'end_index', -1),
                        "source": "annotation"
                    }
                    citations.append(citation)
        except Exception as e:
            print(f"Annotation extraction error: {e}")
        
        return citations
    
    @staticmethod
    def validate_citation(citation: Dict) -> List[str]:
        """å¼•ç”¨ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        errors = []
        
        if not citation.get('url', '').startswith('https://'):
            errors.append("URLãŒæœ‰åŠ¹ãªå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        if not citation.get('title', '').strip():
            errors.append("ã‚¿ã‚¤ãƒˆãƒ«ãŒç©ºã§ã™")
        
        start_idx = citation.get('start_index', -1)
        end_idx = citation.get('end_index', -1)
        
        if start_idx < 0 or end_idx < 0:
            errors.append("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç„¡åŠ¹ã§ã™")
        elif start_idx >= end_idx:
            errors.append("start_index ãŒ end_index ä»¥ä¸Šã§ã™")
        
        return errors
    
    @staticmethod
    def get_cited_text(text: str, citation: Dict) -> str:
        """å¼•ç”¨ç®‡æ‰€ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾— - ã‚ˆã‚ŠæŸ”è»Ÿãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"""
        try:
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸå¼•ç”¨ã®å ´åˆ
            if citation.get('source') == 'markdown_link':
                # URLã¨ã‚¿ã‚¤ãƒˆãƒ«ãŒå­˜åœ¨ã™ã‚Œã°æœ‰åŠ¹ã¨ã¿ãªã™
                if citation.get('url') and citation.get('title'):
                    return citation.get('title', '')
            
            # é€šå¸¸ã®annotationã®å ´åˆ
            start_idx = citation.get('start_index', -1)
            end_idx = citation.get('end_index', -1)
            
            if start_idx >= 0 and end_idx > start_idx and end_idx <= len(text):
                return text[start_idx:end_idx]
            else:
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç„¡åŠ¹ãªå ´åˆã€ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯éƒ¨åˆ†çš„ãªãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã‚’è©¦è¡Œ
                title = citation.get('title', '')
                if title and title in text:
                    return title
                
                url = citation.get('url', '')
                if url and url in text:
                    # URLã®å‰å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                    url_pos = text.find(url)
                    start_pos = max(0, url_pos - 50)
                    end_pos = min(len(text), url_pos + len(url) + 50)
                    return text[start_pos:end_pos]
                
                return ""
        except Exception as e:
            print(f"Text extraction error: {e}")
            return ""


class TestWebSearch:
    """Webæ¤œç´¢å®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.client = WebSearchTestClient()
    
    def test_basic_web_search(self) -> TestResult:
        """åŸºæœ¬çš„ãªWebæ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
        test_name = "basic_web_search"
        
        try:
            # æ¤œç´¢å®Ÿè¡Œ
            start_time = time.time()
            input_items = [self.client.text("user", "ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹")]
            output_text = self.client.generate_response_with_WebSearch(input_items)
            
            # å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚‚å–å¾—ï¼ˆæ§‹é€ ç¢ºèªç”¨ï¼‰
            response = self.client.execute_web_search_with_response("ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹")
            execution_time = time.time() - start_time
            
            # æ¤œç´¢å®Ÿè¡Œã®ç¢ºèª
            search_executed = False
            for item in response.output:
                if hasattr(item, 'type') and item.type == "web_search_call":
                    if getattr(item, 'status', '') == "completed":
                        search_executed = True
                        break
            
            details = {
                "search_executed": search_executed,
                "execution_time": round(execution_time, 2),
                "output_text": output_text[:500] + "..." if len(output_text) > 500 else output_text
            }
            
            status = "PASS" if search_executed else "FAIL"
            errors = [] if search_executed else ["Webæ¤œç´¢ãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
            
        except Exception as e:
            status = "FAIL"
            details = {"error": str(e)}
            errors = [f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"]
        
        return TestResult(test_name, status, details, errors)
    
    def test_search_context_size(self) -> TestResult:
        """æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºãƒ†ã‚¹ãƒˆ"""
        test_name = "search_context_size"
        
        try:
            results = {}
            
            # åŸºæœ¬çš„ãªWebæ¤œç´¢ãƒ†ã‚¹ãƒˆï¼ˆcontext_sizeã‚ªãƒ—ã‚·ãƒ§ãƒ³ãªã—ï¼‰
            input_items = [self.client.text("user", "OpenAI GPT-4ã®æœ€æ–°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ")]
            
            start_time = time.time()
            output_text = self.client.generate_response_with_WebSearch(input_items)
            execution_time = time.time() - start_time
            
            results["default"] = {
                "execution_time": round(execution_time, 2),
                "response_length": len(output_text),
                "output_preview": output_text[:200] + "..."
            }
            
            details = {"context_size_results": results}
            status = "PASS"
            errors = []
            
        except Exception as e:
            status = "FAIL"
            details = {"error": str(e)}
            errors = [f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"]
        
        return TestResult(test_name, status, details, errors)
    
    def test_user_location(self) -> TestResult:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡å®šãƒ†ã‚¹ãƒˆ"""
        test_name = "user_location"
        
        try:
            # åŸºæœ¬çš„ãªWebæ¤œç´¢ãƒ†ã‚¹ãƒˆï¼ˆlocationæŒ‡å®šãªã—ï¼‰
            input_items = [self.client.text("user", "ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹")]
            output_text = self.client.generate_response_with_WebSearch(input_items)
            
            # æ—¥æœ¬èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡ºï¼ˆç°¡æ˜“ï¼‰
            japanese_chars = len([c for c in output_text if ord(c) > 127])
            total_chars = len(output_text)
            japanese_ratio = japanese_chars / total_chars if total_chars > 0 else 0
            
            details = {
                "japanese_content_ratio": round(japanese_ratio, 3),
                "response_preview": output_text[:300] + "..."
            }
            
            # æ—¥æœ¬èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°PASS
            status = "PASS" if japanese_ratio > 0.1 else "FAIL"
            errors = [] if japanese_ratio > 0.1 else ["æ—¥æœ¬èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒä¸è¶³ã—ã¦ã„ã¾ã™"]
            
        except Exception as e:
            status = "FAIL"
            details = {"error": str(e)}
            errors = [f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"]
        
        return TestResult(test_name, status, details, errors)
    
    def test_forced_tool_use(self) -> TestResult:
        """ãƒ„ãƒ¼ãƒ«ä½¿ç”¨å¼·åˆ¶ãƒ†ã‚¹ãƒˆ"""
        test_name = "forced_tool_use"
        
        try:
            # Webæ¤œç´¢ã‚’æ˜ç¤ºçš„ã«è¦æ±‚ã™ã‚‹è³ªå•ã«å¤‰æ›´
            input_items = [self.client.text("user", "Webæ¤œç´¢ã‚’ä½¿ã£ã¦ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ•™ãˆã¦")]
            output_text = self.client.generate_response_with_WebSearch(input_items)
            
            # å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚‚å–å¾—ï¼ˆæ§‹é€ ç¢ºèªç”¨ï¼‰
            response = self.client.execute_web_search_with_response("Webæ¤œç´¢ã‚’ä½¿ã£ã¦ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ•™ãˆã¦")
            
            # Webæ¤œç´¢ãŒå®Ÿè¡Œã•ã‚ŒãŸã‹ç¢ºèª
            search_forced = False
            for item in response.output:
                if hasattr(item, 'type') and item.type == "web_search_call":
                    if getattr(item, 'status', '') == "completed":
                        search_forced = True
                        break
            
            details = {
                "search_forced": search_forced,
                "response": output_text[:200] + "..." if len(output_text) > 200 else output_text
            }
            
            status = "PASS" if search_forced else "FAIL"
            errors = [] if search_forced else ["å¼·åˆ¶æ¤œç´¢ãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
            
        except Exception as e:
            status = "FAIL"
            details = {"error": str(e)}
            errors = [f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"]
        
        return TestResult(test_name, status, details, errors)


class TestCitationExtraction:
    """å¼•ç”¨æƒ…å ±æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.client = WebSearchTestClient()
        self.extractor = CitationExtractor()
    
    def test_output_structure(self) -> TestResult:
        """å‡ºåŠ›æ§‹é€ æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        test_name = "output_structure"
        
        try:
            # Webæ¤œç´¢å®Ÿè¡Œ
            input_items = [self.client.text("user", "ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹")]
            output_text = self.client.generate_response_with_WebSearch(input_items)
            
            # å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—ï¼ˆæ§‹é€ ç¢ºèªç”¨ï¼‰
            response = self.client.execute_web_search_with_response("ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹")
            
            # æ§‹é€ ã®åˆ†æ
            structure_analysis = {
                "output_items": [],
                "has_web_search_call": False,
                "has_message": False
            }
            
            for item in response.output:
                item_info = {
                    "type": getattr(item, 'type', 'unknown'),
                    "id": getattr(item, 'id', 'no-id')
                }
                
                if hasattr(item, 'type'):
                    if item.type == "web_search_call":
                        structure_analysis["has_web_search_call"] = True
                        item_info["status"] = getattr(item, 'status', 'unknown')
                    elif item.type == "message":
                        structure_analysis["has_message"] = True
                        item_info["role"] = getattr(item, 'role', 'unknown')
                
                structure_analysis["output_items"].append(item_info)
            
            structure_analysis["output_text_length"] = len(response.output_text)
            
            # æ§‹é€ ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            valid_structure = (
                structure_analysis["has_web_search_call"] and 
                structure_analysis["has_message"]
            )
            
            details = structure_analysis
            status = "PASS" if valid_structure else "FAIL"
            errors = [] if valid_structure else ["æœŸå¾…ã•ã‚Œã‚‹æ§‹é€ è¦ç´ ãŒä¸è¶³ã—ã¦ã„ã¾ã™"]
            
        except Exception as e:
            status = "FAIL"
            details = {"error": str(e)}
            errors = [f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"]
        
        return TestResult(test_name, status, details, errors)
    
    def test_annotation_fields(self) -> TestResult:
        """annotationãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        test_name = "annotation_fields"
        
        try:
            # Webæ¤œç´¢å®Ÿè¡Œ
            input_items = [self.client.text("user", "ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹")]
            output_text = self.client.generate_response_with_WebSearch(input_items)
            
            # å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—ï¼ˆannotationæŠ½å‡ºç”¨ï¼‰
            response = self.client.execute_web_search_with_response("ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹")
            
            citations = self.extractor.extract_citations(response)
            
            # å„citationã®æ¤œè¨¼
            valid_citations = 0
            citation_details = []
            
            for i, citation in enumerate(citations):
                errors = self.extractor.validate_citation(citation)
                is_valid = len(errors) == 0
                
                if is_valid:
                    valid_citations += 1
                
                citation_details.append({
                    "index": i,
                    "url": citation.get('url', ''),
                    "title": citation.get('title', '')[:100] + "...",
                    "start_index": citation.get('start_index', -1),
                    "end_index": citation.get('end_index', -1),
                    "is_valid": is_valid,
                    "errors": errors
                })
            
            details = {
                "citations_found": len(citations),
                "valid_citations": valid_citations,
                "citation_details": citation_details
            }
            
            status = "PASS" if len(citations) > 0 and valid_citations > 0 else "FAIL"
            errors = []
            if len(citations) == 0:
                errors.append("å¼•ç”¨æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            elif valid_citations == 0:
                errors.append("æœ‰åŠ¹ãªå¼•ç”¨æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
        except Exception as e:
            status = "FAIL"
            details = {"error": str(e)}
            errors = [f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"]
        
        return TestResult(test_name, status, details, errors)
    
    def test_citation_text_mapping(self) -> TestResult:
        """å¼•ç”¨ã¨ãƒ†ã‚­ã‚¹ãƒˆã®å¯¾å¿œä»˜ã‘ãƒ†ã‚¹ãƒˆ - æ ¹æœ¬çš„ã«å†è¨­è¨ˆ"""
        test_name = "citation_text_mapping"
        
        try:
            # annotation_fieldsãƒ†ã‚¹ãƒˆã¨åŒã˜ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ä¸€è²«æ€§ã‚’ä¿ã¤
            query = "ä»Šæœˆã®AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹"
            
            # å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—
            response = self.client.execute_web_search_with_response(query)
            
            # åŒ…æ‹¬çš„ãªå¼•ç”¨æŠ½å‡ºã‚’å®Ÿè¡Œ
            citations = self.extractor.extract_citations(response)
            output_text = response.output_text
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’åé›†
            debug_info = {
                "query_used": query,
                "output_text_preview": output_text[:200] + "..." if len(output_text) > 200 else output_text,
                "citations_found": len(citations),
                "response_structure": {
                    "has_output": hasattr(response, 'output'),
                    "output_length": len(response.output) if hasattr(response, 'output') else 0,
                    "output_types": [getattr(item, 'type', 'unknown') for item in response.output] if hasattr(response, 'output') else []
                }
            }
            
            mapping_results = []
            successfully_mapped = 0
            
            for i, citation in enumerate(citations):
                # ã‚ˆã‚ŠæŸ”è»Ÿãªãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°
                cited_text = self.extractor.get_cited_text(output_text, citation)
                
                # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸå¼•ç”¨ã®å ´åˆã¯å¸¸ã«æœ‰åŠ¹ã¨ã¿ãªã™
                if citation.get('source') == 'markdown_link':
                    is_valid_mapping = True
                    successfully_mapped += 1
                else:
                    # é€šå¸¸ã®annotationã®å ´åˆã¯å¾“æ¥ã®æ¤œè¨¼
                    is_valid_mapping = len(cited_text.strip()) > 0
                    if is_valid_mapping:
                        successfully_mapped += 1
                
                mapping_results.append({
                    "citation_index": i,
                    "url": citation.get('url', ''),
                    "title": citation.get('title', '')[:50] + "..." if len(citation.get('title', '')) > 50 else citation.get('title', ''),
                    "cited_text": cited_text[:100] + "..." if len(cited_text) > 100 else cited_text,
                    "text_length": len(cited_text),
                    "is_valid_mapping": is_valid_mapping,
                    "source": citation.get('source', 'unknown')
                })
            
            details = {
                "debug_info": debug_info,
                "output_text_length": len(output_text),
                "citations_found": len(citations),
                "citations_mapped": successfully_mapped,
                "mapping_results": mapping_results[:3]  # è©³ç´°è¡¨ç¤ºã¯æœ€åˆã®3ä»¶ã®ã¿
            }
            
            # å¼•ç”¨ãŒè¦‹ã¤ã‹ã‚Šã€å°‘ãªãã¨ã‚‚1ã¤ãŒæ­£ã—ããƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚Œã°PASS
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ã‚‚æœ‰åŠ¹ãªå¼•ç”¨ã¨ã¿ãªã™
            status = "PASS" if len(citations) > 0 and successfully_mapped > 0 else "FAIL"
            errors = []
            if len(citations) == 0:
                errors.append("å¼•ç”¨æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            elif successfully_mapped == 0:
                errors.append("å¼•ç”¨ã¨ãƒ†ã‚­ã‚¹ãƒˆã®å¯¾å¿œä»˜ã‘ãŒã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
        except Exception as e:
            status = "FAIL"
            details = {"error": str(e)}
            errors = [f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"]
            import traceback
            traceback.print_exc()
        
        return TestResult(test_name, status, details, errors)


def run_all_tests() -> List[TestResult]:
    """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    results = []
    
    print("=" * 80)
    print("OpenAI Responses API Webæ¤œç´¢æ©Ÿèƒ½ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)
    
    # Webæ¤œç´¢å®Ÿè¡Œãƒ†ã‚¹ãƒˆ
    print("\nğŸ” Webæ¤œç´¢å®Ÿè¡Œãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    web_search_test = TestWebSearch()
    
    tests = [
        ("åŸºæœ¬æ¤œç´¢", web_search_test.test_basic_web_search),
        # ("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚º", web_search_test.test_search_context_size),
        ("ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡å®š", web_search_test.test_user_location),
        ("å¼·åˆ¶ãƒ„ãƒ¼ãƒ«ä½¿ç”¨", web_search_test.test_forced_tool_use),
    ]
    
    for test_name, test_func in tests:
        print(f"\nå®Ÿè¡Œä¸­: {test_name}...")
        result = test_func()
        results.append(result)
        print(f"çµæœ: {result.status}")
        if result.errors:
            print(f"ã‚¨ãƒ©ãƒ¼: {result.errors}")
    
    # å¼•ç”¨æƒ…å ±æŠ½å‡ºãƒ†ã‚¹ãƒˆ
    print("\nğŸ“š å¼•ç”¨æƒ…å ±æŠ½å‡ºãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    citation_test = TestCitationExtraction()
    
    citation_tests = [
        ("å‡ºåŠ›æ§‹é€ æ¤œè¨¼", citation_test.test_output_structure),
        ("annotationæ¤œè¨¼", citation_test.test_annotation_fields),
        ("å¼•ç”¨ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œ", citation_test.test_citation_text_mapping),
    ]
    
    for test_name, test_func in citation_tests:
        print(f"\nå®Ÿè¡Œä¸­: {test_name}...")
        result = test_func()
        results.append(result)
        print(f"çµæœ: {result.status}")
        if result.errors:
            print(f"ã‚¨ãƒ©ãƒ¼: {result.errors}")
    
    return results


def generate_test_report(results: List[TestResult]) -> str:
    """ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    total_tests = len(results)
    passed_tests = sum(1 for r in results if r.status == "PASS")
    failed_tests = total_tests - passed_tests
    
    report = f"""
{'=' * 80}
OpenAI Responses API Webæ¤œç´¢æ©Ÿèƒ½ ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ
{'=' * 80}

ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:
  ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}
  æˆåŠŸ: {passed_tests}
  å¤±æ•—: {failed_tests}
  æˆåŠŸç‡: {(passed_tests/total_tests*100):.1f}%

ğŸ“‹ è©³ç´°çµæœ:
"""
    
    for result in results:
        status_icon = "âœ…" if result.status == "PASS" else "âŒ"
        report += f"\n{status_icon} {result.test_name}: {result.status}\n"
        
        if result.details:
            report += "  è©³ç´°:\n"
            for key, value in result.details.items():
                if isinstance(value, (str, int, float, bool)):
                    report += f"    {key}: {value}\n"
                elif isinstance(value, list) and len(value) <= 100:
                    report += f"    {key}: {value}\n"
                else:
                    report += f"    {key}: [è©³ç´°ãƒ‡ãƒ¼ã‚¿çœç•¥]\n"
        
        if result.errors:
            report += "  ã‚¨ãƒ©ãƒ¼:\n"
            for error in result.errors:
                report += f"    - {error}\n"
    
    return report


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        results = run_all_tests()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»è¡¨ç¤º
        report = generate_test_report(results)
        print(report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open("web_search_test_report.txt", "w", encoding="utf-8") as f:
            f.write(report)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: web_search_test_report.txt")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()