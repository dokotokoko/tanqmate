from fastapi import FastAPI, HTTPException, Depends, status, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import sys
import os
import json
import logging
from datetime import datetime, timedelta, timezone
import asyncio
import uvicorn
from supabase import create_client, Client
from dotenv import load_dotenv
from functools import lru_cache
import time
from collections import deque

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from module.llm_api import learning_plannner
from prompt.prompt import system_prompt, dev_system_prompt

# ä¸¦åˆ—å‡¦ç†ãƒ»éåŒæœŸå‡¦ç†çµ±åˆã®ãŸã‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from async_helpers import (
    AsyncDatabaseHelper,
    AsyncProjectContextBuilder,
    parallel_fetch_context_and_history,
    parallel_save_chat_logs
)
from module.async_llm_api import get_async_llm_client
from optimized_endpoints import optimized_chat_with_ai
from conversation_agent.optimized_conversation_agent import optimized_chat_with_conversation_agent

# æ¢ç©¶å­¦ç¿’APIãƒ«ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from inquiry_api import router as inquiry_router

# ä¼šè©±ç®¡ç†APIã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from conversation_api import (
    ConversationManager,
    ConversationCreate,
    ConversationUpdate,
    ConversationResponse,
    ConversationListResponse,
    MessageResponse
)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®šï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
logging.basicConfig(
    level=logging.INFO,  # DEBUGç”¨ã«INFOãƒ¬ãƒ™ãƒ«ã«å¤‰æ›´
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Phase 1: ãƒ—ãƒ¼ãƒ«æ©Ÿèƒ½ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®å®Œå…¨äº’æ›æ€§ä¿æŒï¼‰
try:
    from phase1_llm_system import (
        get_phase1_manager,
        safe_generate_response,
        log_system_status
    )
    PHASE1_AVAILABLE = True
    logger.info("âœ… Phase 1ãƒ—ãƒ¼ãƒ«æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    PHASE1_AVAILABLE = False
    logger.info(f"â„¹ï¸ Phase 1ãƒ—ãƒ¼ãƒ«æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™: {e}")

from ontology.ontology_graph import (
    InquiryOntologyGraph, Node, Edge, NodeType, RelationType
)
from ontology.ontology_adapter import OntologyAdapter
from ontology.ontology_orchestrator import OntologyOrchestrator
from ontology.conversation_filter import ConversationFilter, AdvancedConversationFilter
from ontology_inference_logger import (
    OntologyInferenceLogger, InferenceStepType, get_inference_logger
)
ONTOLOGY_GRAPH_AVAILABLE = True
logger.info("âœ… ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨å¯èƒ½ã§ã™")

# =====================
# Config/Feature flags
# =====================
# History window size for chat context (kept small to control latency/cost)
CHAT_HISTORY_LIMIT_DEFAULT = int(os.environ.get("CHAT_HISTORY_LIMIT_DEFAULT", "50"))
CHAT_HISTORY_LIMIT_MAX = int(os.environ.get("CHAT_HISTORY_LIMIT_MAX", "100"))

# Message length guard for /chat
MAX_CHAT_MESSAGE_LENGTH = int(os.environ.get("MAX_CHAT_MESSAGE_LENGTH", "2000"))

# Simple in-memory rate limiting for /chat (per user+IP)
ENABLE_CHAT_RATE_LIMIT = os.environ.get("ENABLE_CHAT_RATE_LIMIT", "true").lower() == "true"
RATE_LIMIT_WINDOW_SEC = int(os.environ.get("CHAT_RATE_LIMIT_WINDOW_SEC", "60"))
RATE_LIMIT_MAX_REQUESTS = int(os.environ.get("CHAT_RATE_LIMIT_MAX", "20"))

# Phase 1: AIå¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    # åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®conversation_agentãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from conversation_agent import ConversationOrchestrator
    CONVERSATION_AGENT_AVAILABLE = True
    logger.info("å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError:
    try:
        # ä»£æ›¿ãƒ‘ã‚¹ï¼ˆmain.pyã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹å ´åˆï¼‰
        from conversation_agent import ConversationOrchestrator
        CONVERSATION_AGENT_AVAILABLE = True
        logger.info("å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼ˆä»£æ›¿ãƒ‘ã‚¹ï¼‰")
    except ImportError as e:
        CONVERSATION_AGENT_AVAILABLE = False
        logger.warning(f"å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")

# æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ï¼‰
ENABLE_CONVERSATION_AGENT = True

# èªè¨¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥
auth_cache = {}
AUTH_CACHE_TTL = 300  # 5åˆ†

app = FastAPI(
    title="æ¢Qãƒ¡ã‚¤ãƒˆ API (æœ€é©åŒ–ç‰ˆ)",
    description="AIæ¢ç©¶å­¦ç¿’æ”¯æ´ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰",
    version="1.1.0",
    docs_url="/docs",  # æœ¬ç•ªã§ã¯ç„¡åŠ¹åŒ–ã‚’æ¤œè¨
    redoc_url="/redoc"  # æœ¬ç•ªã§ã¯ç„¡åŠ¹åŒ–ã‚’æ¤œè¨
)

# æ¢ç©¶å­¦ç¿’APIãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ç™»éŒ²
app.include_router(inquiry_router)

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«æä¾›
app.mount("/static", StaticFiles(directory="static"), name="static")

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
app.add_middleware(GZipMiddleware, minimum_size=1000)  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹åœ§ç¸®

# CORSè¨­å®š
# é–‹ç™ºç’°å¢ƒã§Nginxãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ä¸è¦
# æœ¬ç•ªç’°å¢ƒã‚„ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ãªå ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ãã ã•ã„
if os.environ.get("ENABLE_CORS", "false").lower() == "true":
    app.add_middleware(
        CORSMiddleware,
        allow_origins=[
            "http://localhost:5173", 
            "http://localhost:3000",
            "http://127.0.0.1:8080",
            "http://localhost:8080",
            "https://demo.tanqmates.org"
        ],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ¼ãƒ 
security = HTTPBearer()

# In-memory rate limiting store
_rate_limit_store: dict = {}

async def chat_rate_limiter(request: Request, current_user: int = Depends(security)):
    """Simple per-user+IP rate limiter for /chat.
    Uses a sliding window over RATE_LIMIT_WINDOW_SEC seconds.
    """
    if not ENABLE_CHAT_RATE_LIMIT:
        return

    try:
        # Extract user id from bearer token (already required by Depends(security))
        token = current_user.credentials if hasattr(current_user, "credentials") else None
        user_key = str(token) if token else request.client.host
    except Exception:
        user_key = request.client.host

    ip = request.client.host if request.client else "unknown"
    key = f"{user_key}:{ip}"

    now = time.time()
    window_start = now - RATE_LIMIT_WINDOW_SEC

    dq = _rate_limit_store.get(key)
    if dq is None:
        dq = deque()
        _rate_limit_store[key] = dq

    # Drop old entries
    while dq and dq[0] < window_start:
        dq.popleft()

    if len(dq) >= RATE_LIMIT_MAX_REQUESTS:
        raise HTTPException(status_code=429, detail="Rate limit exceeded. Please slow down.")

    dq.append(now)

# === Pydanticãƒ¢ãƒ‡ãƒ« ===
# ï¼ˆå…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚’ãã®ã¾ã¾ç¶™æ‰¿ï¼‰

# èªè¨¼é–¢é€£
class UserLogin(BaseModel):
    username: str
    access_code: str

class UserRegister(BaseModel):
    username: str
    password: str
    confirm_password: str

class UserResponse(BaseModel):
    id: int
    username: str
    message: str

# ãƒãƒ£ãƒƒãƒˆé–¢é€£
class ChatMessage(BaseModel):
    message: str
    context: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    timestamp: str
    token_usage: Optional[Dict[str, Any]] = None
    context_metadata: Optional[Dict[str, Any]] = None
    # Conversation agent metadata (optional)
    support_type: Optional[str] = None
    selected_acts: Optional[List[str]] = None
    state_snapshot: Optional[Dict[str, Any]] = None
    project_plan: Optional[Dict[str, Any]] = None
    decision_metadata: Optional[Dict[str, Any]] = None
    metrics: Optional[Dict[str, Any]] = None

# Conversation Agentå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¤œè¨¼ç”¨ï¼‰
class ConversationAgentRequest(BaseModel):
    """å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¤œè¨¼ç”¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    message: str
    project_id: Optional[int] = None
    include_history: bool = True
    history_limit: int = 50
    debug_mode: bool = False  # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å«ã‚ã‚‹ã‹
    mock_mode: bool = True  # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã™ã‚‹ã‹

class ConversationAgentResponse(BaseModel):
    """å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¤œè¨¼ç”¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    response: str
    timestamp: str
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    support_type: str
    selected_acts: List[str]
    state_snapshot: Dict[str, Any]
    project_plan: Optional[Dict[str, Any]]
    decision_metadata: Dict[str, Any]
    metrics: Dict[str, Any]
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    debug_info: Optional[Dict[str, Any]] = None
    # å±¥æ­´æƒ…å ±
    conversation_id: Optional[str] = None
    history_count: int = 0
    # ã‚¨ãƒ©ãƒ¼æƒ…å ±
    error: Optional[str] = None
    warning: Optional[str] = None

class ChatHistoryResponse(BaseModel):
    id: int
    sender: str
    message: str
    context_data: Optional[str]
    created_at: str

# ConversationResponse ã¯å‰Šé™¤ï¼ˆchat_conversationsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½¿ç”¨ã—ãªã„ãŸã‚ï¼‰

# ãƒ¡ãƒ¢é–¢é€£
class MemoSave(BaseModel):
    content: str

class MemoResponse(BaseModel):
    id: int
    title: Optional[str] = ""
    content: str
    updated_at: str

# å­¦ç¿’æŒ¯ã‚Šè¿”ã‚Šé–¢é€£ï¼ˆã‚¹ãƒ†ãƒƒãƒ—æ©Ÿèƒ½å‰Šé™¤ã«ã‚ˆã‚Šä¸è¦ï¼‰

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–¢é€£
class ProjectCreate(BaseModel):
    theme: str
    question: Optional[str] = None
    hypothesis: Optional[str] = None

class ProjectUpdate(BaseModel):
    theme: Optional[str] = None
    question: Optional[str] = None
    hypothesis: Optional[str] = None

class ProjectResponse(BaseModel):
    id: int
    theme: str
    question: Optional[str]
    hypothesis: Optional[str]
    created_at: str
    updated_at: str
    memo_count: int

# ãƒãƒ«ãƒãƒ¡ãƒ¢é–¢é€£
class MultiMemoCreate(BaseModel):
    title: str
    content: str
    project_id: Optional[int] = None

class MultiMemoUpdate(BaseModel):
    title: Optional[str] = None
    content: Optional[str] = None
    version: Optional[int] = None
    requestId: Optional[str] = None
    seq: Optional[int] = None

class MultiMemoResponse(BaseModel):
    id: int
    title: str
    content: str
    tags: List[str]
    project_id: Optional[int]
    created_at: str
    updated_at: str

# ãƒ†ãƒ¼ãƒæ·±æ˜ã‚Šé–¢é€£
class ThemeDeepDiveRequest(BaseModel):
    theme: str
    parent_theme: str
    depth: int
    path: List[str]
    user_interests: List[str] = []

class ThemeDeepDiveResponse(BaseModel):
    suggestions: List[str]
    context_info: Dict[str, Any]

# ã‚¯ã‚¨ã‚¹ãƒˆé–¢é€£
class QuestResponse(BaseModel):
    id: int
    title: str
    description: str
    category: str
    difficulty: int
    points: int
    required_evidence: str
    icon_name: Optional[str]
    is_active: bool
    created_at: str
    updated_at: str

class UserQuestResponse(BaseModel):
    id: int
    user_id: int
    quest_id: int
    status: str
    progress: int
    quest: QuestResponse
    started_at: Optional[str]
    completed_at: Optional[str]
    created_at: str
    updated_at: str

class QuestSubmissionCreate(BaseModel):
    description: str
    file_url: Optional[str] = None
    reflection_data: Optional[Dict[str, Any]] = None

class QuestSubmissionResponse(BaseModel):
    id: int
    user_quest_id: int
    quest_id: int
    description: str
    file_url: Optional[str]
    reflection_data: Optional[Dict[str, Any]]
    status: str
    points_awarded: int
    submitted_at: str

class UserQuestStart(BaseModel):
    quest_id: int

# ç®¡ç†è€…é–¢é€£
class AdminUserCreate(BaseModel):
    username: str
    password: str

# =============================================================================
# ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ãƒ¢ãƒ‡ãƒ«
# =============================================================================

class OntologyChatRequest(BaseModel):
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•å¯¾è©±ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    message: str
    use_graph_mode: bool = True
    project_id: Optional[int] = None
    debug_mode: bool = False
    include_inference_log: bool = True

class OntologyChatResponse(BaseModel):
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•å¯¾è©±ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    response: str
    timestamp: str
    # ã‚°ãƒ©ãƒ•é–¢é€£æƒ…å ±
    graph_context: Optional[Dict[str, Any]] = None
    current_node: Optional[Dict[str, Any]] = None
    next_suggestions: List[Dict[str, Any]] = Field(default_factory=list)
    # æ¨è«–è©³ç´°
    inference_trace_id: Optional[str] = None
    inference_steps: List[Dict[str, Any]] = Field(default_factory=list)
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    support_type: str = ""
    selected_acts: List[str] = Field(default_factory=list)
    processing_time_ms: int = 0
    success: bool = True
    error_message: Optional[str] = None

class NodeCreateRequest(BaseModel):
    """ãƒãƒ¼ãƒ‰ä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    type: str = Field(..., description="ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ— (Goal, Question, Hypothesis, Method, Data, Insight, Reflection, Will, Need, Topic, Challenge)")
    text: str = Field(..., description="ãƒãƒ¼ãƒ‰ã®å†…å®¹")
    clarity: float = Field(0.5, ge=0.0, le=1.0)
    depth: float = Field(0.5, ge=0.0, le=1.0)
    alignment_goal: float = Field(0.5, ge=0.0, le=1.0)
    tags: List[str] = Field(default_factory=list)

class NodeResponse(BaseModel):
    """ãƒãƒ¼ãƒ‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    id: str
    type: str
    text: str
    student_id: str
    timestamp: str
    state: str
    confidence: float
    clarity: float
    depth: float
    alignment_goal: float
    tags: List[str]
    metadata: Dict[str, Any]

class EdgeCreateRequest(BaseModel):
    """ã‚¨ãƒƒã‚¸ä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    src_node_id: str = Field(..., description="ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ID")
    dst_node_id: str = Field(..., description="å®›å…ˆãƒãƒ¼ãƒ‰ID")
    relation_type: str = Field(..., description="é–¢ä¿‚ã‚¿ã‚¤ãƒ— (generates, motivates, grounds, frames, leads_to, is_tested_by, results_in, leads_to_insight, modifies, aligned_with)")
    confidence: float = Field(0.7, ge=0.0, le=1.0)

class EdgeResponse(BaseModel):
    """ã‚¨ãƒƒã‚¸ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    src: str
    rel: str
    dst: str
    confidence: float
    timestamp: str
    metadata: Dict[str, Any]

class GraphStateResponse(BaseModel):
    """ã‚°ãƒ©ãƒ•çŠ¶æ…‹ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    user_id: str
    current_node: Optional[NodeResponse] = None
    progress: Dict[str, Any]
    suggestions: List[Dict[str, Any]]
    nodes: List[NodeResponse]
    edges: List[EdgeResponse]
    statistics: Dict[str, Any]

class InferenceTraceResponse(BaseModel):
    """æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    trace_id: str
    user_id: str
    conversation_id: str
    user_message: str
    start_time: str
    end_time: Optional[str] = None
    steps: List[Dict[str, Any]]
    final_response: str
    total_processing_time_ms: int
    graph_state_before: Dict[str, Any]
    graph_state_after: Dict[str, Any]
    success: bool
    error_message: Optional[str] = None

class InferenceVisualizationResponse(BaseModel):
    """æ¨è«–å¯è¦–åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    trace_info: Dict[str, Any]
    step_flow: List[Dict[str, Any]]
    graph_changes: Dict[str, Any]
    performance_stats: Dict[str, Any]
    confidence_scores: List[float]

# === ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ===
llm_client = None
supabase: Client = None
# memory_manager: MemoryManager = None  # ä½¿ç”¨ã—ãªã„
async_llm_client = None  # éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

# Phase 1: ãƒ—ãƒ¼ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ—¢å­˜ã®llm_clientã¯å®Œå…¨ã«ç¶­æŒï¼‰
phase1_llm_manager = None  # Phase 1 ãƒ—ãƒ¼ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè¿½åŠ ï¼‰

# Phase 1: å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
conversation_orchestrator = None

# ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
conversation_manager: Optional[ConversationManager] = None

# ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ 
ontology_adapter: Optional['OntologyAdapter'] = None
enhanced_orchestrator: Optional['OntologyOrchestrator'] = None
inference_logger: Optional['OntologyInferenceLogger'] = None
conversation_filter: Optional['AdvancedConversationFilter'] = None

@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®åˆæœŸåŒ–ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    global llm_client, supabase, conversation_orchestrator, phase1_llm_manager, async_llm_client, conversation_manager, enhanced_orchestrator
    
    try:
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³è¨­å®šæœ€é©åŒ–ï¼‰
        supabase_url = os.environ.get("SUPABASE_URL")
        supabase_key = os.environ.get("SUPABASE_KEY")
        
        if not supabase_url or not supabase_key:
            raise ValueError("Supabaseç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
        supabase = create_client(supabase_url, supabase_key)
        
        # ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        conversation_manager = ConversationManager(supabase)
        logger.info("âœ… ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
        # LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        llm_client = learning_plannner()
        
        # === Phase 1: ãƒ—ãƒ¼ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆè¿½åŠ ï¼‰===
        if PHASE1_AVAILABLE:
            try:
                # Phase 1ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆæ—¢å­˜ã®llm_clientã‚’ä½¿ç”¨ï¼‰
                phase1_llm_manager = await get_phase1_manager()
                await phase1_llm_manager.initialize(existing_legacy_client=llm_client)
                
                # åˆæœŸåŒ–çŠ¶æ³ã‚’ãƒ­ã‚°å‡ºåŠ›
                if os.environ.get("ENABLE_LLM_POOL", "false").lower() == "true":
                    logger.info("âœ… Phase 1: ãƒ—ãƒ¼ãƒ«æ©Ÿèƒ½ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
                else:
                    logger.info("â„¹ï¸ Phase 1: ãƒ—ãƒ¼ãƒ«æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ï¼‰")
                    
            except Exception as e:
                logger.error(f"âš ï¸ Phase 1åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã§ç¶™ç¶šï¼‰: {e}")
                phase1_llm_manager = None
        
        # éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        try:
            async_llm_client = get_async_llm_client(pool_size=10)
            logger.info("âœ… éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            async_llm_client = None
        
        # Phase 1: å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–
        if ENABLE_CONVERSATION_AGENT and CONVERSATION_AGENT_AVAILABLE:
            try:
                conversation_orchestrator = ConversationOrchestrator(
                    llm_client=llm_client,
                    use_mock=True  # Phase 1ã§ã¯ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰
                )
                logger.info("âœ… å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†ï¼ˆãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ï¼‰")
            except Exception as e:
                logger.error(f"âŒ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
                conversation_orchestrator = None
        else:
            if not ENABLE_CONVERSATION_AGENT:
                logger.info("âš ï¸ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ï¼ˆç’°å¢ƒå¤‰æ•°ENABLE_CONVERSATION_AGENT=falseï¼‰")
            if not CONVERSATION_AGENT_AVAILABLE:
                logger.info("âš ï¸ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ä¸å¯ã§ã™")
        
        # ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        global ontology_adapter, enhanced_orchestrator, inference_logger, conversation_filter
        
        # ä¼šè©±ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æœ€åˆã«åˆæœŸåŒ–ï¼ˆã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã¨ç‹¬ç«‹ï¼‰
        conversation_filter = AdvancedConversationFilter()
        logger.info("âœ… ä¼šè©±ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæœŸåŒ–æˆåŠŸ")
        
        if ONTOLOGY_GRAPH_AVAILABLE:
            try:
                # ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
                ontology_adapter = OntologyAdapter(
                    ontology_path="ontology.yaml",
                    constraints_path="constraints.yaml"
                )
                
                # æ¨è«–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
                inference_logger = get_inference_logger()
                
                # EnhancedOrchestratorV2ã‚’åˆæœŸåŒ–
                enhanced_orchestrator = OntologyOrchestrator(
                    llm_client=llm_client,
                    use_mock=False,
                    use_graph=True,
                    use_advanced_inference=True,
                    ontology_path="ontology.yaml",
                    constraints_path="constraints.yaml"
                )
                
                logger.info("âœ… ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ï¼ˆEnhancedOrchestratorV2ï¼‰åˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                logger.error(f"âŒ ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
                ontology_adapter = None
                enhanced_orchestrator = None
                inference_logger = None
                # conversation_filter ã¯ã™ã§ã«åˆæœŸåŒ–æ¸ˆã¿ãªã®ã§ None ã«ã—ãªã„
        else:
            logger.info("âš ï¸ ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ã¯åˆ©ç”¨ä¸å¯ã§ã™")
        
        logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Œäº†ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰")
        
    except Exception as e:
        logger.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        raise e

@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    global auth_cache
    auth_cache.clear()
    logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†")

def get_current_user_cached(credentials: HTTPAuthorizationCredentials = Depends(security)) -> int:
    """èªè¨¼å‡¦ç†ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
    global auth_cache
    
    token = credentials.credentials
    current_time = time.time()
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ç¢ºèª
    if token in auth_cache:
        cached_data = auth_cache[token]
        if current_time - cached_data["timestamp"] < AUTH_CACHE_TTL:
            return cached_data["user_id"]
        else:
            # æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
            del auth_cache[token]
    
    try:
        user_id = int(token)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼å­˜åœ¨ç¢ºèªï¼ˆæœ€é©åŒ–ï¼šå¿…è¦æœ€å°é™ã®ã‚¯ã‚¨ãƒªï¼‰
        result = supabase.table("users").select("id").eq("id", user_id).limit(1).execute()
        
        if not result.data:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ç„¡åŠ¹ãªèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã§ã™"
            )
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        auth_cache[token] = {
            "user_id": user_id,
            "timestamp": current_time
        }
        
        return user_id
        
    except ValueError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç„¡åŠ¹ãªãƒˆãƒ¼ã‚¯ãƒ³å½¢å¼ã§ã™"
        )
    except Exception as e:
        import traceback
        error_detail = f"èªè¨¼ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {str(e)}"
        logger.error(f"{error_detail}\nTraceback: {traceback.format_exc()}")
        
        # Supabaseæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è©³ç´°ã‚’è¿”ã™
        if "connection" in str(e).lower() or "timeout" in str(e).lower():
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail=f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"
            )
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"èªè¨¼å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )

def validate_supabase():
    """Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æœ‰åŠ¹æ€§ç¢ºèª"""
    if not supabase:
        raise HTTPException(status_code=500, detail="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

@lru_cache(maxsize=100)
def get_cached_result(table: str, user_id: int, cache_key: str):
    """ç°¡å˜ãªã‚¯ã‚¨ãƒªçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    # å®Ÿè£…ã¯çœç•¥ï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã«è¿½åŠ ï¼‰
    pass

def handle_database_error(error: Exception, operation: str):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    error_detail = f"{operation}ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(error)}"
    logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ - {operation}: {error}")
    print(f"Database Error - {operation}: {error}")
    import traceback
    print(f"Database Error Traceback: {traceback.format_exc()}")
    raise HTTPException(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        detail=error_detail
    )

async def get_or_create_global_chat_session(user_id: int) -> str:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®AIãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—ã¾ãŸã¯ä½œæˆï¼ˆæ–°ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œï¼‰"""
    try:
        # æ–°ã—ã„ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
        if conversation_manager:
            # æœ€æ–°ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªä¼šè©±ã‚’å–å¾—
            conversations = await conversation_manager.list_conversations(
                user_id=user_id,
                limit=1,
                offset=0,
                is_active=True
            )
            
            if conversations.conversations:
                return conversations.conversations[0].id
            else:
                # æ–°ã—ã„ä¼šè©±ã‚’ä½œæˆ
                return await conversation_manager.create_conversation(
                    user_id=user_id,
                    title="AIãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³",
                    metadata={"session_type": "global_chat", "auto_created": True}
                )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—¢å­˜ã®å®Ÿè£…
            existing_conv = supabase.table("chat_conversations").select("*").eq("user_id", user_id).execute()
            
            if existing_conv.data:
                return existing_conv.data[0]["id"]
            else:
                # æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
                new_conv_data = {
                    "user_id": user_id,
                    "title": "AIãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³"
                }
                new_conv = supabase.table("chat_conversations").insert(new_conv_data).execute()
                return new_conv.data[0]["id"] if new_conv.data else None
                
    except Exception as e:
        logger.error(f"ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—/ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        raise

async def update_conversation_timestamp(conversation_id: str):
    """conversationã®æœ€çµ‚æ›´æ–°æ™‚åˆ»ã‚’æ›´æ–°"""
    try:
        await asyncio.to_thread(
            lambda: supabase.table("chat_conversations").update({
                "updated_at": datetime.now().isoformat()
            }).eq("id", conversation_id).execute()
        )
    except Exception as e:
        logger.error(f"conversation timestampæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

# === ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£… ===

# ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ï¼ˆå„ªå…ˆåº¦ã‚’ä¸Šã’ã‚‹ãŸã‚æœ€åˆã«å®šç¾©ï¼‰
@app.get("/ontology-test", response_class=HTMLResponse)
async def ontology_test_page():
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸"""
    logger.info("ğŸ“Š /ontology-test ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")
    try:
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        file_path = "static/ontology-test.html"
        logger.info(f"ğŸ“‚ HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {file_path}")
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
        logger.info("âœ… HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
        return HTMLResponse(content=content)
    except FileNotFoundError:
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ä»£æ›¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        logger.error("âŒ ontology-test.html ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return HTMLResponse(
            content="""
            <!DOCTYPE html>
            <html>
            <head>
                <title>ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ - ã‚¨ãƒ©ãƒ¼</title>
                <meta charset="utf-8">
            </head>
            <body>
                <h1>ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</h1>
                <p>ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ (static/ontology-test.html) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚</p>
                <p><a href="/docs">API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</a> | <a href="/">ãƒ›ãƒ¼ãƒ </a></p>
            </body>
            </html>
            """,
            status_code=404
        )

# ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ï¼ˆAPIçµŒç”±ã‚¢ã‚¯ã‚»ã‚¹ç”¨ï¼‰
@app.get("/api/ontology-test", response_class=HTMLResponse)
async def api_ontology_test_page():
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ï¼ˆAPIçµŒç”±ï¼‰"""
    logger.info("ğŸ“Š /api/ontology-test ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")
    try:
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        file_path = "static/ontology-test.html"
        logger.info(f"ğŸ“‚ HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {file_path}")
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
        logger.info("âœ… HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
        return HTMLResponse(content=content)
    except FileNotFoundError:
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ä»£æ›¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        logger.error("âŒ ontology-test.html ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return HTMLResponse(
            content="""
            <!DOCTYPE html>
            <html>
            <head>
                <title>ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ - ã‚¨ãƒ©ãƒ¼</title>
                <meta charset="utf-8">
            </head>
            <body>
                <h1>ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</h1>
                <p>ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ (static/ontology-test.html) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚</p>
                <p><a href="/docs">API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</a> | <a href="/">ãƒ›ãƒ¼ãƒ </a></p>
            </body>
            </html>
            """,
            status_code=404
        )

@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    return {"message": "æ¢Qãƒ¡ã‚¤ãƒˆ APIï¼ˆæœ€é©åŒ–ç‰ˆï¼‰", "status": "running", "version": "1.1.0"}

@app.get("/health")
async def health_check():
    """nginxç”¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "healthy", "message": "OK"}

@app.post("/auth/login", response_model=UserResponse)
async def login(user_data: UserLogin):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    validate_supabase()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªæœ€é©åŒ–ï¼šå¿…è¦ãªåˆ—ã®ã¿å–å¾—
        result = supabase.table("users").select("id, username").eq("username", user_data.username).limit(1).execute()
        
        if not result.data:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ã‚¢ã‚¯ã‚»ã‚¹ã‚³ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“"
            )
        
        user = result.data[0]
        
        # ã‚¢ã‚¯ã‚»ã‚¹ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‰ç¢ºèª
        # æ³¨æ„: æœ¬ç•ªç’°å¢ƒã§ã¯å¿…ãšãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–ã—ã¦æ¯”è¼ƒã—ã¦ãã ã•ã„
        result_password = supabase.table("users").select("password").eq("id", user["id"]).execute()
        if not result_password.data or result_password.data[0]["password"] != user_data.access_code:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ã‚¢ã‚¯ã‚»ã‚¹ã‚³ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“"
            )
        
        # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸæ™‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
        token = str(user["id"])
        auth_cache[token] = {
            "user_id": user["id"],
            "timestamp": time.time()
        }
        
        return UserResponse(
            id=user["id"],
            username=user["username"],
            message="ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸ"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†")

@app.post("/auth/register", response_model=UserResponse, status_code=status.HTTP_201_CREATED)
async def register(user_data: UserRegister):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼æ–°è¦ç™»éŒ²ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    validate_supabase()
    
    try:
        # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        if user_data.password != user_data.confirm_password:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¨ç¢ºèªç”¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ã¾ã›ã‚“"
            )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        existing_user = supabase.table("users").select("id").eq("username", user_data.username).limit(1).execute()
        if existing_user.data:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯æ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™"
            )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
        result = supabase.table("users").insert({
            "username": user_data.username,
            "password": user_data.password
        }).execute()
        
        if result.data and len(result.data) > 0:
            new_user = result.data[0]
            response = UserResponse(
                id=new_user["id"],
                username=new_user["username"],
                message="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼æ¢Qãƒ¡ã‚¤ãƒˆã¸ã‚ˆã†ã“ãï¼"
            )
            
            # æ˜ç¤ºçš„ã«JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦è¿”ã™
            from fastapi.responses import JSONResponse
            return JSONResponse(
                status_code=status.HTTP_201_CREATED,
                content=response.dict()
            )
        else:
            raise HTTPException(status_code=500, detail="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™»éŒ²")

@app.post("/chat", response_model=ChatResponse, dependencies=[Depends(chat_rate_limiter)])
async def chat_with_ai(
    chat_data: ChatMessage,
    current_user: int = Depends(get_current_user_cached)
):
    """AIã¨ã®ãƒãƒ£ãƒƒãƒˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    
    try:
        # æœ€é©åŒ–ç‰ˆã‚’ä½¿ç”¨
        result = await optimized_chat_with_ai(
            chat_data=chat_data,
            current_user=current_user,
            supabase=supabase,
            llm_client=llm_client,
            conversation_orchestrator=conversation_orchestrator,
            ENABLE_CONVERSATION_AGENT=ENABLE_CONVERSATION_AGENT,
            MAX_CHAT_MESSAGE_LENGTH=MAX_CHAT_MESSAGE_LENGTH
        )
        
        # æ—¢å­˜ã®ChatResponseãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        return ChatResponse(
            response=result.response,
            timestamp=result.timestamp,
            token_usage=result.token_usage,
            context_metadata=result.context_metadata,
            support_type=result.support_type,
            selected_acts=result.selected_acts,
            state_snapshot=result.state_snapshot,
            project_plan=result.project_plan,
            decision_metadata=result.decision_metadata,
            metrics=result.metrics
        )
    except:
        # æ—¢å­˜ã®å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        try:
            validate_supabase()
            
            if llm_client is None:
                raise HTTPException(
                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                    detail="LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
                )
            
            # ç‹¬ç«‹ã—ãŸAIãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆãƒšãƒ¼ã‚¸éä¾å­˜ï¼‰
            conversation_id = await get_or_create_global_chat_session(current_user)
        
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¯DBã‹ã‚‰å–å¾—ã›ãšã€ä¼šè©±å±¥æ­´ã‹ã‚‰æ¨æ¸¬ã™ã‚‹æ–¹é‡ã«å¤‰æ›´
            project_context = None
            project = None
            project_id = None
            
            logger.info(f"ğŸ“ ç‹¬ç«‹ AIãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ - ãƒšãƒ¼ã‚¸éä¾å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³")
            
            # éå»ã®å¯¾è©±å±¥æ­´ã‚’å–å¾—ï¼ˆæœ€é©åŒ–ï¼š20-30ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åˆ¶é™ï¼‰
            history_limit = 30  # å±¥æ­´å–å¾—ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹
            history_response = supabase.table("chat_logs").select("id, sender, message, created_at").eq("conversation_id", conversation_id).order("created_at", desc=False).limit(history_limit).execute()
            conversation_history = history_response.data if history_response.data is not None else []

            if conversation_history is None:
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’æ®‹ã™
                print(f"Warning: conversation_history is None for conversation_id: {conversation_id}")
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æº–å‚™
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æº–å‚™ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¯å«ã‚ãªã„ï¼‰
            messages = [{"role": "system", "content": dev_system_prompt}]
            if conversation_history:  # None ã¾ãŸã¯ç©ºãƒªã‚¹ãƒˆã®ãƒã‚§ãƒƒã‚¯
                for history_msg in conversation_history:
                    role = "user" if history_msg["sender"] == "user" else "assistant"
                    messages.append({"role": role, "content": history_msg["message"]})

            user_message = chat_data.message
            
            # Guard: message size limit to protect backend/LLM
            if user_message is not None and len(user_message) > MAX_CHAT_MESSAGE_LENGTH:
                raise HTTPException(status_code=400, detail="Message too long")

            messages.append({"role": "user", "content": user_message})
            context_metadata = None
            
            # ä¿å­˜ç”¨ã®context_dataä½œæˆï¼ˆç‹¬ç«‹è¨­è¨ˆç‰ˆï¼‰
            context_data_dict = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "session_type": "global_chat",  # ç‹¬ç«‹ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³
                "independent": True  # ãƒšãƒ¼ã‚¸éä¾å­˜ã®ãƒ•ãƒ©ã‚°
            }
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’DBã«ä¿å­˜
            user_message_data = {
                "user_id": current_user,
                "page": "legacy",  # å»ƒæ­¢äºˆå®š: context_dataã‚’ä½¿ç”¨
                "sender": "user",
                "message": chat_data.message,
                "conversation_id": conversation_id,
                "context_data": json.dumps(context_data_dict, ensure_ascii=False)
            }
            await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(user_message_data).execute())
            
            # agent_payloadã‚’åˆæœŸåŒ–
            agent_payload = {}
            
            # å¾“æ¥ã®å‡¦ç†
            response = llm_client.generate_response(messages)
            ai_context_data = {
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨ˆç®—ï¼ˆä½¿ç”¨ã—ãªã„ï¼‰
            token_usage = None
            
            ai_message_data = {
                "user_id": current_user,
                "page": "legacy",  # å»ƒæ­¢äºˆå®š: context_dataã‚’ä½¿ç”¨
                "sender": "assistant",
                "message": response,
                "conversation_id": conversation_id,
                "context_data": json.dumps(ai_context_data, ensure_ascii=False)
            }
            await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(ai_message_data).execute())
            
            # conversationã®æœ€çµ‚æ›´æ–°æ™‚åˆ»ã‚’æ›´æ–°
            try:
                await update_conversation_timestamp(conversation_id)
            except Exception as e:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ›´æ–°ã‚¨ãƒ©ãƒ¼ã¯è­¦å‘Šãƒ­ã‚°ã®ã¿ï¼ˆãƒãƒ£ãƒƒãƒˆè‡ªä½“ã¯æ­£å¸¸ã«å‡¦ç†ï¼‰
                logger.warning(f"conversation timestamp update failed: {e}")
            
            return ChatResponse(
                response=response,
                timestamp=datetime.now(timezone.utc).isoformat(),
                token_usage=token_usage,
                context_metadata=context_metadata,
                **agent_payload
            )
        except HTTPException:
            raise
        except Exception as e:
            print(f"Chat API Error: {str(e)}")
            print(f"Error type: {type(e)}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            handle_database_error(e, "AIå¿œç­”ã®ç”Ÿæˆ")

@app.get("/chat/history", response_model=List[ChatHistoryResponse])
async def get_chat_history(
    limit: Optional[int] = 50,
    before: Optional[str] = None,
    current_user: int = Depends(get_current_user_cached)
):
    """å¯¾è©±å±¥æ­´å–å¾—"""
    try:
        validate_supabase()
        
        # å…¨å±¥æ­´ã‚’å–å¾—
        query = supabase.table("chat_logs").select("id, sender, message, context_data, created_at").eq("user_id", current_user)
        
        query = query.order("created_at", desc=False).limit(limit or 50)
        result = query.execute()
        
        items = [
            ChatHistoryResponse(
                id=item["id"],
                sender=item["sender"],
                message=item["message"],
                context_data=item.get("context_data"),
                created_at=item["created_at"]
            )
            for item in result.data
        ]
        # reverse to chronological order (oldest first)
        return list(reversed(items))
    except Exception as e:
        handle_database_error(e, "å¯¾è©±å±¥æ­´ã®å–å¾—")

# ===================================================================
# ä¼šè©±ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ===================================================================

@app.post("/conversations", response_model=ConversationResponse)
async def create_conversation(
    conversation_data: ConversationCreate,
    current_user: int = Depends(get_current_user_cached)
):
    """æ–°ã—ã„ä¼šè©±ã‚’ä½œæˆ"""
    try:
        validate_supabase()
        
        if not conversation_manager:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        conversation_id = await conversation_manager.create_conversation(
            user_id=current_user,
            title=conversation_data.title,
            metadata=conversation_data.metadata
        )
        
        # ä½œæˆã—ãŸä¼šè©±æƒ…å ±ã‚’å–å¾—ã—ã¦è¿”ã™
        conversation = await conversation_manager.get_conversation(conversation_id, current_user)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¼šè©±ã®ä½œæˆå¾Œã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
        
        return conversation
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¼šè©±ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ä¼šè©±ã®ä½œæˆ")

@app.get("/conversations", response_model=ConversationListResponse)
async def list_conversations(
    limit: Optional[int] = 20,
    offset: Optional[int] = 0,
    is_active: Optional[bool] = None,
    current_user: int = Depends(get_current_user_cached)
):
    """ä¼šè©±ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    try:
        validate_supabase()
        
        if not conversation_manager:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶é™
        limit = min(limit or 20, 100)  # æœ€å¤§100ä»¶
        offset = max(offset or 0, 0)
        
        return await conversation_manager.list_conversations(
            user_id=current_user,
            limit=limit,
            offset=offset,
            is_active=is_active
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¼šè©±ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ä¼šè©±ãƒªã‚¹ãƒˆã®å–å¾—")

@app.get("/conversations/{conversation_id}", response_model=ConversationResponse)
async def get_conversation(
    conversation_id: str,
    current_user: int = Depends(get_current_user_cached)
):
    """æŒ‡å®šã—ãŸä¼šè©±ã®è©³ç´°ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        if not conversation_manager:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        conversation = await conversation_manager.get_conversation(conversation_id, current_user)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè©±ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"
            )
        
        return conversation
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¼šè©±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ä¼šè©±ã®å–å¾—")

@app.put("/conversations/{conversation_id}", response_model=ConversationResponse)
async def update_conversation(
    conversation_id: str,
    update_data: ConversationUpdate,
    current_user: int = Depends(get_current_user_cached)
):
    """ä¼šè©±æƒ…å ±ã‚’æ›´æ–°"""
    try:
        validate_supabase()
        
        if not conversation_manager:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        success = await conversation_manager.update_conversation(
            conversation_id=conversation_id,
            user_id=current_user,
            update_data=update_data
        )
        
        if not success:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè©±ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
        
        # æ›´æ–°å¾Œã®ä¼šè©±æƒ…å ±ã‚’å–å¾—ã—ã¦è¿”ã™
        conversation = await conversation_manager.get_conversation(conversation_id, current_user)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¼šè©±ã®æ›´æ–°å¾Œã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
        
        return conversation
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¼šè©±æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ä¼šè©±ã®æ›´æ–°")

@app.delete("/conversations/{conversation_id}")
async def delete_conversation(
    conversation_id: str,
    current_user: int = Depends(get_current_user_cached)
):
    """ä¼šè©±ã‚’å‰Šé™¤ï¼ˆè«–ç†å‰Šé™¤ï¼‰"""
    try:
        validate_supabase()
        
        if not conversation_manager:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        success = await conversation_manager.delete_conversation(conversation_id, current_user)
        
        if not success:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè©±ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
        
        return {"message": "ä¼šè©±ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "conversation_id": conversation_id}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¼šè©±å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ä¼šè©±ã®å‰Šé™¤")

@app.get("/conversations/{conversation_id}/messages", response_model=List[MessageResponse])
async def get_conversation_messages(
    conversation_id: str,
    limit: Optional[int] = 50,
    offset: Optional[int] = 0,
    current_user: int = Depends(get_current_user_cached)
):
    """ä¼šè©±ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        if not conversation_manager:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ä¼šè©±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶é™
        limit = min(limit or 50, 200)  # æœ€å¤§200ä»¶
        offset = max(offset or 0, 0)
        
        return await conversation_manager.get_messages(
            conversation_id=conversation_id,
            user_id=current_user,
            limit=limit,
            offset=offset
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å–å¾—")

@app.post("/memos", response_model=MemoResponse)
async def save_memo(
    memo_data: MemoSave,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¡ãƒ¢ã®ä¿å­˜ï¼ˆpage_memosãƒ†ãƒ¼ãƒ–ãƒ«éå¯¾å¿œã®ãŸã‚ç„¡åŠ¹åŒ–ï¼‰"""
    try:
        validate_supabase()
        
        # page_memosãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
        raise HTTPException(
            status_code=status.HTTP_501_NOT_IMPLEMENTED,
            detail="page_memosãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒ¢ä¿å­˜ã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒ¢æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ¡ãƒ¢ã®ä¿å­˜")

@app.get("/memos/{memo_id}", response_model=MemoResponse)
async def get_memo_by_id(
    memo_id: str,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¡ãƒ¢IDãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒ¢å–å¾—"""
    try:
        validate_supabase()
        
        # memo_idãŒæ•°å€¤ã®å ´åˆã¯memosãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—
        try:
            id_value = int(memo_id)
            result = supabase.table("memos").select("id, title, content, updated_at, created_at").eq("id", id_value).eq("user_id", current_user).execute()
            
            if result.data:
                memo = result.data[0]
                return MemoResponse(
                    id=memo["id"],
                    title=memo.get("title") or "",
                    content=memo.get("content") or "",
                    updated_at=memo.get("updated_at") or memo.get("created_at") or datetime.now(timezone.utc).isoformat()
                )
            else:
                # ãƒ¡ãƒ¢ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®ãƒ¡ãƒ¢ã‚’è¿”ã™
                return MemoResponse(
                    id=0,
                    title="",
                    content="",
                    updated_at=datetime.now(timezone.utc).isoformat()
                )
        except ValueError:
            # memo_idãŒæ•°å€¤ã§ãªã„å ´åˆã¯ç©ºã®ãƒ¡ãƒ¢ã‚’è¿”ã™
            return MemoResponse(
                id=0,
                title="",
                content="",
                updated_at=datetime.now(timezone.utc).isoformat()
            )
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ¡ãƒ¢ã®å–å¾—")

@app.get("/memos", response_model=List[MemoResponse])
async def get_all_memos(current_user: int = Depends(get_current_user_cached)):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨ãƒ¡ãƒ¢å–å¾—ï¼ˆmemosãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—ï¼‰"""
    try:
        validate_supabase()
        
        # memosãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨ãƒ¡ãƒ¢ã‚’å–å¾—
        result = supabase.table("memos").select("id, title, content, updated_at, created_at").eq("user_id", current_user).order("updated_at", desc=True).execute()
        
        return [
            MemoResponse(
                id=memo["id"],
                title=memo.get("title") or "",
                content=memo.get("content") or "",
                updated_at=memo.get("updated_at") or memo.get("created_at") or datetime.now(timezone.utc).isoformat()
            )
            for memo in result.data
        ]
    except Exception as e:
        handle_database_error(e, "å…¨ãƒ¡ãƒ¢ã®å–å¾—")

# =============================================================================
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†API
# =============================================================================

@app.post("/projects", response_model=ProjectResponse)
async def create_project(
    project_data: ProjectCreate,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ"""
    try:
        validate_supabase()
        
        result = supabase.table('projects').insert({
            'user_id': current_user,
            'theme': project_data.theme,
            'question': project_data.question,
            'hypothesis': project_data.hypothesis
        }).execute()
        
        if result.data:
            project = result.data[0]
            return ProjectResponse(
                id=project['id'],
                theme=project['theme'],
                question=project['question'],
                hypothesis=project['hypothesis'],
                created_at=project['created_at'],
                updated_at=project['updated_at'],
                memo_count=0
            )
        else:
            raise HTTPException(status_code=500, detail="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ")

@app.get("/users/{user_id}/projects", response_model=List[ProjectResponse])
async def get_user_projects(
    user_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§å–å¾—"""
    if user_id != current_user:
        raise HTTPException(status_code=403, detail="ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")

    try:
        validate_supabase()
        
        result = supabase.table('projects').select('id, user_id, theme, question, hypothesis, created_at, updated_at').eq('user_id', user_id).order('updated_at', desc=True).execute()
        
        projects = []
        for project in result.data:
            memo_count_result = supabase.table('memos').select('id', count='exact').eq('project_id', project['id']).execute()
            memo_count = memo_count_result.count if memo_count_result.count else 0
            
            projects.append(ProjectResponse(
                id=project['id'],
                theme=project['theme'],
                question=project['question'],
                hypothesis=project['hypothesis'],
                created_at=project['created_at'],
                updated_at=project['updated_at'],
                memo_count=memo_count
            ))
        
        return projects
    except Exception as e:
        handle_database_error(e, "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã®å–å¾—")

@app.get("/projects/{project_id}", response_model=ProjectResponse)
async def get_project(
    project_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ç‰¹å®šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå–å¾—"""
    try:
        validate_supabase()
        
        result = supabase.table('projects').select('id, user_id, theme, question, hypothesis, created_at, updated_at').eq('id', project_id).eq('user_id', current_user).execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        project = result.data[0]
        memo_count_result = supabase.table('memos').select('id', count='exact').eq('project_id', project['id']).execute()
        memo_count = memo_count_result.count if memo_count_result.count else 0
        
        return ProjectResponse(
            id=project['id'],
            theme=project['theme'],
            question=project['question'],
            hypothesis=project['hypothesis'],
            created_at=project['created_at'],
            updated_at=project['updated_at'],
            memo_count=memo_count
        )
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å–å¾—")

@app.put("/projects/{project_id}", response_model=ProjectResponse)
async def update_project(
    project_id: int,
    project_data: ProjectUpdate,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ›´æ–°"""
    try:
        validate_supabase()
        
        update_data = project_data.dict(exclude_unset=True)
        
        if not update_data:
            raise HTTPException(status_code=400, detail="æ›´æ–°ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
        
        result = supabase.table('projects').update(update_data).eq('id', project_id).eq('user_id', current_user).execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return await get_project(project_id, current_user)
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ›´æ–°")

@app.delete("/projects/{project_id}")
async def delete_project(
    project_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‰Šé™¤"""
    try:
        validate_supabase()
        
        result = supabase.table('projects').delete().eq('id', project_id).eq('user_id', current_user).execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return {"message": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸ"}
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å‰Šé™¤")

# =============================================================================
# ãƒãƒ«ãƒãƒ¡ãƒ¢ç®¡ç†API
# =============================================================================

@app.post("/projects/{project_id}/memos", response_model=MultiMemoResponse)
async def create_project_memo(
    project_id: int,
    memo_data: MultiMemoCreate,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¡ãƒ¢ä½œæˆ"""
    try:
        validate_supabase()
        
        result = supabase.table('memos').insert({
            'user_id': current_user,
            'project_id': project_id,
            'title': memo_data.title,
            'content': memo_data.content
        }).execute()
        
        if result.data:
            memo = result.data[0]
            return MultiMemoResponse(
                id=memo['id'],
                title=memo.get('title') or '',
                content=memo.get('content') or '',
                tags=[],
                project_id=memo.get('project_id', project_id),
                created_at=memo.get('created_at') or datetime.now(timezone.utc).isoformat(),
                updated_at=memo.get('updated_at') or datetime.now(timezone.utc).isoformat()
            )
        else:
            raise HTTPException(status_code=500, detail="ãƒ¡ãƒ¢ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ¡ãƒ¢ã®ä½œæˆ")

@app.get("/projects/{project_id}/memos", response_model=List[MultiMemoResponse])
async def get_project_memos(
    project_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¡ãƒ¢ä¸€è¦§å–å¾—"""
    try:
        validate_supabase()
        
        result = supabase.table('memos').select('id, title, content, project_id, created_at, updated_at').eq('project_id', project_id).eq('user_id', current_user).order('updated_at', desc=True).execute()
        
        return [
            MultiMemoResponse(
                id=memo['id'],
                title=memo.get('title') or '',
                content=memo.get('content') or '',
                tags=[],
                project_id=memo.get('project_id', project_id),
                created_at=memo.get('created_at') or datetime.now(timezone.utc).isoformat(),
                updated_at=memo.get('updated_at') or datetime.now(timezone.utc).isoformat()
            )
            for memo in result.data
        ]
    except Exception as e:
        handle_database_error(e, "ãƒ¡ãƒ¢ä¸€è¦§ã®å–å¾—")

@app.get("/memos/{memo_id}", response_model=MultiMemoResponse)
async def get_memo(
    memo_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ç‰¹å®šãƒ¡ãƒ¢å–å¾—"""
    try:
        validate_supabase()
        
        logger.info(f"ãƒ¡ãƒ¢å–å¾—é–‹å§‹: memo_id={memo_id}, user_id={current_user}")
        
        result = supabase.table('memos').select('id, title, content, project_id, created_at, updated_at').eq('id', memo_id).eq('user_id', current_user).execute()
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªçµæœ: count={result.count if result.count else 0}, data_length={len(result.data) if result.data else 0}")
        
        if not result.data:
            logger.warning(f"ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: memo_id={memo_id}, user_id={current_user}")
            raise HTTPException(status_code=404, detail="ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        memo = result.data[0]
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ç¢ºèªã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
        logger.info(f"ãƒ¡ãƒ¢ãƒ‡ãƒ¼ã‚¿å–å¾—: keys={list(memo.keys())}, values={memo}")
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ç¢ºèª
        if 'id' not in memo:
            logger.error(f"ãƒ¡ãƒ¢IDãŒå­˜åœ¨ã—ã¾ã›ã‚“: {memo.keys()}")
            raise HTTPException(status_code=500, detail="ãƒ¡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚¨ãƒ©ãƒ¼")
        
        response = MultiMemoResponse(
            id=memo['id'],
            title=memo.get('title') or '',
            content=memo.get('content') or '',
            tags=[],
            project_id=memo.get('project_id'),
            created_at=memo.get('created_at') or datetime.now(timezone.utc).isoformat(),
            updated_at=memo.get('updated_at') or datetime.now(timezone.utc).isoformat()
        )
        
        logger.info(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆæˆåŠŸ: memo_id={memo['id']}")
        return response
    except HTTPException:
        raise
    except KeyError as e:
        logger.error(f"ãƒ¡ãƒ¢ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}, ãƒ¡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼: {memo.keys() if 'memo' in locals() else 'N/A'}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ãƒ¡ãƒ¢ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{e}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        )
    except ValueError as e:
        logger.error(f"ãƒ¡ãƒ¢ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ãƒ¡ãƒ¢ã®ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ (ãƒ¡ãƒ¢å–å¾—): {type(e).__name__}: {str(e)}")
        handle_database_error(e, "ãƒ¡ãƒ¢ã®å–å¾—")

@app.put("/memos/{memo_id}", response_model=MultiMemoResponse)
async def update_memo(
    memo_id: int,
    memo_data: MultiMemoUpdate,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¡ãƒ¢æ›´æ–°ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    try:
        validate_supabase()
        
        update_data = memo_data.dict(exclude_unset=True)
        
        if not update_data:
            raise HTTPException(status_code=400, detail="æ›´æ–°ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
        from datetime import datetime, timezone
        update_data['updated_at'] = datetime.now(timezone.utc).isoformat()
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–: execute()ã‚’åˆ†é›¢
        import asyncio
        try:
            result = await asyncio.wait_for(
                asyncio.to_thread(
                    lambda: supabase.table('memos').update(update_data).eq('id', memo_id).eq('user_id', current_user).execute()
                ),
                timeout=30.0  # 30ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
        except asyncio.TimeoutError:
            logger.error(f"ãƒ¡ãƒ¢æ›´æ–°ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: memo_id={memo_id}, user_id={current_user}")
            raise HTTPException(status_code=504, detail="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        
        if not result.data:
            raise HTTPException(status_code=404, detail="ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return await get_memo(memo_id, current_user)
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ¡ãƒ¢ã®æ›´æ–°")

@app.delete("/memos/{memo_id}")
async def delete_memo(
    memo_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¡ãƒ¢å‰Šé™¤"""
    try:
        validate_supabase()
        
        result = supabase.table('memos').delete().eq('id', memo_id).eq('user_id', current_user).execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return {"message": "ãƒ¡ãƒ¢ãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸ"}
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ãƒ¡ãƒ¢ã®å‰Šé™¤")

# =============================================================================
# ãƒ†ãƒ¼ãƒæ·±æ˜ã‚Šãƒ„ãƒ¼ãƒ«ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
# =============================================================================

@app.post("/framework-games/theme-deep-dive/suggestions", response_model=ThemeDeepDiveResponse)
async def generate_theme_suggestions(
    request: ThemeDeepDiveRequest,
    current_user: int = Depends(get_current_user_cached)
):
    """æ¢ç©¶ãƒ†ãƒ¼ãƒã®æ·±æ˜ã‚Šææ¡ˆã‚’ç”Ÿæˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    try:
        validate_supabase()
        
        if llm_client is None:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰ï¼ˆæœ€é©åŒ–ï¼šåŠ¹ç‡çš„ãªæŒ‡ç¤ºï¼‰
        system_prompt_theme = """ã‚ãªãŸã¯æ¢ç©¶å­¦ç¿’ã®å°‚é–€å®¶ã§ã™ã€‚
ç”Ÿå¾’ãŒæŒã£ã¦ã„ã‚‹ãƒ†ãƒ¼ãƒã«å¯¾ã—ã¦ã€ã‚ˆã‚Šå…·ä½“çš„ã§èˆˆå‘³æ·±ã„æ–¹å‘æ€§ã‚’ææ¡ˆã™ã‚‹å½¹å‰²ãŒã‚ã‚Šã¾ã™ã€‚
ææ¡ˆã¯æ¢ç©¶å¯èƒ½ã§é«˜æ ¡ç”Ÿã«ã¨ã£ã¦ç†è§£å¯èƒ½ã§å®Ÿè¡Œå¯èƒ½ãªã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚"""

        depth_guidance = "ã‚ˆã‚Šå…·ä½“çš„ãªæ¢ç©¶ã®åˆ‡ã‚Šå£ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚" if request.depth >= 2 else "å…·ä½“çš„ãªé ˜åŸŸã‚„å´é¢ã«åˆ†ã‘ã¦ãã ã•ã„ã€‚"
        interest_context = f"\nç”Ÿå¾’ã®èˆˆå‘³é–¢å¿ƒ: {', '.join(request.user_interests)}" if request.user_interests else ""
        
        user_prompt = f"""æ¢ç©¶ãƒ†ãƒ¼ãƒã€Œ{request.theme}ã€ã«ã¤ã„ã¦ã€æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã®å…·ä½“çš„ãªæ¢ç©¶ã®æ–¹å‘æ€§ã‚’5ã€œ7å€‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚

{depth_guidance}
{interest_context}

ä»¥ä¸‹ã®å½¢å¼ã§ææ¡ˆã—ã¦ãã ã•ã„ï¼š
1. [ææ¡ˆå†…å®¹]
2. [ææ¡ˆå†…å®¹]
...

å„ææ¡ˆã¯30æ–‡å­—ä»¥å†…ã§ã€ç”Ÿå¾’ãŒèˆˆå‘³ã‚’æŒã¡ã‚„ã™ã„è¡¨ç¾ã«ã—ã¦ãã ã•ã„ã€‚"""

        # LLMã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆæœ€é©åŒ–ï¼šå±¥æ­´ãªã—ã§åŠ¹ç‡åŒ–ï¼‰
        messages = [
            {"role": "system", "content": system_prompt_theme},
            {"role": "user", "content": user_prompt}
        ]
        
        response = llm_client.generate_response(messages)
        
        # å¿œç­”ã®ãƒ‘ãƒ¼ã‚¹ï¼ˆæœ€é©åŒ–ï¼šåŠ¹ç‡çš„ãªæ­£è¦è¡¨ç¾ï¼‰
        import re
        suggestions = []
        for line in response.strip().split('\n'):
            match = re.match(r'^\d+\.\s*(.+)$', line.strip())
            if match:
                suggestion = match.group(1).strip()
                if suggestion and len(suggestion) <= 50:
                    suggestions.append(suggestion)
        
        # æœ€ä½5å€‹ã€æœ€å¤§7å€‹ã«èª¿æ•´
        if len(suggestions) < 5:
            default_suggestions = [
                f"{request.theme}ã®ç¤¾ä¼šçš„å½±éŸ¿",
                f"{request.theme}ã®æŠ€è¡“çš„å´é¢",
                f"{request.theme}ã¨ç’°å¢ƒã®é–¢ä¿‚",
                f"{request.theme}ã®æ­´å²çš„èƒŒæ™¯",
                f"{request.theme}ã®æœªæ¥äºˆæ¸¬"
            ]
            for ds in default_suggestions:
                if len(suggestions) >= 7:
                    break
                if ds not in suggestions:
                    suggestions.append(ds)
        elif len(suggestions) > 7:
            suggestions = suggestions[:7]
        
        context_info = {
            "depth": request.depth,
            "suggestions_count": len(suggestions)
        }
        
        return ThemeDeepDiveResponse(
            suggestions=suggestions,
            context_info=context_info
        )
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ææ¡ˆã®ç”Ÿæˆ")

@app.post("/framework-games/theme-deep-dive/save-selection")
async def save_theme_selection(
    request: Dict[str, Any],
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ†ãƒ¼ãƒé¸æŠã®ä¿å­˜"""
    try:
        theme = request.get("theme")
        path = request.get("path", [])
        
        if not theme:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ãƒ†ãƒ¼ãƒãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        # ã“ã“ã§ã¯é¸æŠã‚’è¨˜éŒ²ã™ã‚‹ã ã‘ã§ã€ç‰¹ã«DBã¸ã®ä¿å­˜ã¯è¡Œã‚ãªã„
        # å°†æ¥çš„ã«DBã«ä¿å­˜ã™ã‚‹å ´åˆã¯ã“ã“ã«å®Ÿè£…ã‚’è¿½åŠ 
        logger.info(f"User {current_user} selected theme: {theme}, path: {path}")
        
        return {"message": "é¸æŠãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ", "theme": theme, "path": path}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ãƒ†ãƒ¼ãƒé¸æŠã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="é¸æŠã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"
        )

# =============================================================================
# ã‚¯ã‚¨ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ API
# =============================================================================

@app.get("/quests", response_model=List[QuestResponse])
async def get_quests(
    category: Optional[str] = None,
    difficulty: Optional[int] = None,
    current_user: int = Depends(get_current_user_cached)
):
    """åˆ©ç”¨å¯èƒ½ãªã‚¯ã‚¨ã‚¹ãƒˆä¸€è¦§ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        query = supabase.table("quests").select("*").eq("is_active", True)
        
        if category:
            query = query.eq("category", category)
        if difficulty:
            query = query.eq("difficulty", difficulty)
        
        result = query.order("difficulty", desc=False).order("points", desc=False).execute()
        
        return [
            QuestResponse(
                id=quest["id"],
                title=quest["title"],
                description=quest["description"],
                category=quest["category"],
                difficulty=quest["difficulty"],
                points=quest["points"],
                required_evidence=quest["required_evidence"],
                icon_name=quest.get("icon_name"),
                is_active=quest["is_active"],
                created_at=quest["created_at"],
                updated_at=quest["updated_at"]
            )
            for quest in result.data
        ]
    except Exception as e:
        handle_database_error(e, "ã‚¯ã‚¨ã‚¹ãƒˆä¸€è¦§ã®å–å¾—")

@app.get("/quests/{quest_id}", response_model=QuestResponse)
async def get_quest(
    quest_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ç‰¹å®šã®ã‚¯ã‚¨ã‚¹ãƒˆè©³ç´°ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        result = supabase.table("quests").select("*").eq("id", quest_id).eq("is_active", True).execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="ã‚¯ã‚¨ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        quest = result.data[0]
        return QuestResponse(
            id=quest["id"],
            title=quest["title"],
            description=quest["description"],
            category=quest["category"],
            difficulty=quest["difficulty"],
            points=quest["points"],
            required_evidence=quest["required_evidence"],
            icon_name=quest.get("icon_name"),
            is_active=quest["is_active"],
            created_at=quest["created_at"],
            updated_at=quest["updated_at"]
        )
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ã‚¯ã‚¨ã‚¹ãƒˆè©³ç´°ã®å–å¾—")

@app.get("/user-quests", response_model=List[UserQuestResponse])
async def get_user_quests(
    status: Optional[str] = None,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ã‚¹ãƒˆé€²æ—ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        query = supabase.table("user_quests").select("""
            id, user_id, quest_id, status, progress, started_at, completed_at, created_at, updated_at,
            quests!user_quests_quest_id_fkey (
                id, title, description, category, difficulty, points, required_evidence, icon_name, is_active, created_at, updated_at
            )
        """).eq("user_id", current_user)
        
        if status:
            query = query.eq("status", status)
        
        result = query.order("updated_at", desc=True).execute()
        
        return [
            UserQuestResponse(
                id=uq["id"],
                user_id=uq["user_id"],
                quest_id=uq["quest_id"],
                status=uq["status"],
                progress=uq["progress"] or 0,
                quest=QuestResponse(
                    id=uq["quests"]["id"],
                    title=uq["quests"]["title"],
                    description=uq["quests"]["description"],
                    category=uq["quests"]["category"],
                    difficulty=uq["quests"]["difficulty"],
                    points=uq["quests"]["points"],
                    required_evidence=uq["quests"]["required_evidence"],
                    icon_name=uq["quests"].get("icon_name"),
                    is_active=uq["quests"]["is_active"],
                    created_at=uq["quests"]["created_at"],
                    updated_at=uq["quests"]["updated_at"]
                ),
                started_at=uq.get("started_at"),
                completed_at=uq.get("completed_at"),
                created_at=uq["created_at"],
                updated_at=uq["updated_at"]
            )
            for uq in result.data
        ]
    except Exception as e:
        handle_database_error(e, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ã‚¹ãƒˆã®å–å¾—")

@app.post("/user-quests/start", response_model=UserQuestResponse)
async def start_quest(
    quest_data: UserQuestStart,
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚¯ã‚¨ã‚¹ãƒˆã‚’é–‹å§‹"""
    try:
        validate_supabase()
        
        # ã‚¯ã‚¨ã‚¹ãƒˆãŒå­˜åœ¨ã—ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ãƒã‚§ãƒƒã‚¯
        quest_result = supabase.table("quests").select("*").eq("id", quest_data.quest_id).eq("is_active", True).execute()
        if not quest_result.data:
            raise HTTPException(status_code=404, detail="ã‚¯ã‚¨ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # æ—¢ã«é–‹å§‹æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        existing_result = supabase.table("user_quests").select("id, status").eq("user_id", current_user).eq("quest_id", quest_data.quest_id).execute()
        
        if existing_result.data:
            existing_quest = existing_result.data[0]
            if existing_quest["status"] == "completed":
                raise HTTPException(status_code=400, detail="ã“ã®ã‚¯ã‚¨ã‚¹ãƒˆã¯æ—¢ã«å®Œäº†ã—ã¦ã„ã¾ã™")
            elif existing_quest["status"] == "in_progress":
                raise HTTPException(status_code=400, detail="ã“ã®ã‚¯ã‚¨ã‚¹ãƒˆã¯æ—¢ã«é€²è¡Œä¸­ã§ã™")
            else:
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                update_result = supabase.table("user_quests").update({
                    "status": "in_progress",
                    "started_at": datetime.now(timezone.utc).isoformat(),
                    "progress": 0
                }).eq("id", existing_quest["id"]).execute()
        else:
            # æ–°è¦ä½œæˆ
            update_result = supabase.table("user_quests").insert({
                "user_id": current_user,
                "quest_id": quest_data.quest_id,
                "status": "in_progress",
                "started_at": datetime.now(timezone.utc).isoformat(),
                "progress": 0
            }).execute()
        
        if not update_result.data:
            raise HTTPException(status_code=500, detail="ã‚¯ã‚¨ã‚¹ãƒˆã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # æ›´æ–°ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ã‚¹ãƒˆã‚’å–å¾—
        result = supabase.table("user_quests").select("""
            id, user_id, quest_id, status, progress, started_at, completed_at, created_at, updated_at,
            quests!user_quests_quest_id_fkey (
                id, title, description, category, difficulty, points, required_evidence, icon_name, is_active, created_at, updated_at
            )
        """).eq("id", update_result.data[0]["id"]).execute()
        
        if not result.data:
            raise HTTPException(status_code=500, detail="é–‹å§‹ã—ãŸã‚¯ã‚¨ã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        uq = result.data[0]
        return UserQuestResponse(
            id=uq["id"],
            user_id=uq["user_id"],
            quest_id=uq["quest_id"],
            status=uq["status"],
            progress=uq["progress"] or 0,
            quest=QuestResponse(
                id=uq["quests"]["id"],
                title=uq["quests"]["title"],
                description=uq["quests"]["description"],
                category=uq["quests"]["category"],
                difficulty=uq["quests"]["difficulty"],
                points=uq["quests"]["points"],
                required_evidence=uq["quests"]["required_evidence"],
                icon_name=uq["quests"].get("icon_name"),
                is_active=uq["quests"]["is_active"],
                created_at=uq["quests"]["created_at"],
                updated_at=uq["quests"]["updated_at"]
            ),
            started_at=uq.get("started_at"),
            completed_at=uq.get("completed_at"),
            created_at=uq["created_at"],
            updated_at=uq["updated_at"]
        )
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ã‚¯ã‚¨ã‚¹ãƒˆã®é–‹å§‹")

@app.post("/user-quests/{user_quest_id}/submit", response_model=QuestSubmissionResponse)
async def submit_quest(
    user_quest_id: int,
    submission_data: QuestSubmissionCreate,
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚¯ã‚¨ã‚¹ãƒˆã®æˆæœç‰©ã‚’æå‡º"""
    try:
        validate_supabase()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ã‚¹ãƒˆã®å­˜åœ¨ç¢ºèª
        uq_result = supabase.table("user_quests").select("id, user_id, quest_id, status").eq("id", user_quest_id).eq("user_id", current_user).execute()
        
        if not uq_result.data:
            raise HTTPException(status_code=404, detail="ã‚¯ã‚¨ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        user_quest = uq_result.data[0]
        
        if user_quest["status"] != "in_progress":
            raise HTTPException(status_code=400, detail="é€²è¡Œä¸­ã®ã‚¯ã‚¨ã‚¹ãƒˆã®ã¿æå‡ºã§ãã¾ã™")
        
        # ã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—
        quest_result = supabase.table("quests").select("points").eq("id", user_quest["quest_id"]).execute()
        quest_points = quest_result.data[0]["points"] if quest_result.data else 1000
        
        # æå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        submission_result = supabase.table("quest_submissions").insert({
            "user_quest_id": user_quest_id,
            "user_id": current_user,
            "quest_id": user_quest["quest_id"],
            "description": submission_data.description,
            "file_url": submission_data.file_url,
            "reflection_data": submission_data.reflection_data,
            "status": "approved",  # è‡ªå‹•æ‰¿èª
            "points_awarded": quest_points
        }).execute()
        
        if not submission_result.data:
            raise HTTPException(status_code=500, detail="æå‡ºã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ã‚¹ãƒˆã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å®Œäº†ã«æ›´æ–°
        supabase.table("user_quests").update({
            "status": "completed",
            "progress": 100,
            "completed_at": datetime.now(timezone.utc).isoformat()
        }).eq("id", user_quest_id).execute()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒ³ãƒˆã‚’æ›´æ–°
        try:
            profile_result = supabase.table("user_learning_profiles").select("total_points").eq("user_id", current_user).execute()
            
            if profile_result.data:
                current_points = profile_result.data[0]["total_points"] or 0
                supabase.table("user_learning_profiles").update({
                    "total_points": current_points + quest_points,
                    "last_activity": datetime.now(timezone.utc).isoformat()
                }).eq("user_id", current_user).execute()
            else:
                # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°è¦ä½œæˆ
                supabase.table("user_learning_profiles").insert({
                    "user_id": current_user,
                    "total_points": quest_points,
                    "last_activity": datetime.now(timezone.utc).isoformat()
                }).execute()
        except Exception as e:
            logger.warning(f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ã«å¤±æ•—: {e}")
        
        submission = submission_result.data[0]
        return QuestSubmissionResponse(
            id=submission["id"],
            user_quest_id=submission["user_quest_id"],
            quest_id=submission["quest_id"],
            description=submission["description"],
            file_url=submission.get("file_url"),
            reflection_data=submission.get("reflection_data"),
            status=submission["status"],
            points_awarded=submission["points_awarded"],
            submitted_at=submission["submitted_at"]
        )
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "ã‚¯ã‚¨ã‚¹ãƒˆã®æå‡º")

@app.get("/user-quests/{user_quest_id}/submission", response_model=QuestSubmissionResponse)
async def get_quest_submission(
    user_quest_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚¯ã‚¨ã‚¹ãƒˆæå‡ºå†…å®¹ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        result = supabase.table("quest_submissions").select("*").eq("user_quest_id", user_quest_id).eq("user_id", current_user).execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="æå‡ºãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        submission = result.data[0]
        return QuestSubmissionResponse(
            id=submission["id"],
            user_quest_id=submission["user_quest_id"],
            quest_id=submission["quest_id"],
            description=submission["description"],
            file_url=submission.get("file_url"),
            reflection_data=submission.get("reflection_data"),
            status=submission["status"],
            points_awarded=submission["points_awarded"],
            submitted_at=submission["submitted_at"]
        )
    except HTTPException:
        raise
    except Exception as e:
        handle_database_error(e, "æå‡ºãƒ‡ãƒ¼ã‚¿ã®å–å¾—")

@app.get("/quest-stats")
async def get_quest_stats(
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚¯ã‚¨ã‚¹ãƒˆçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ã‚¹ãƒˆçµ±è¨ˆ
        user_quests = supabase.table("user_quests").select("status, quests!user_quests_quest_id_fkey(points)").eq("user_id", current_user).execute()
        
        total_quests = len(user_quests.data)
        completed_quests = len([uq for uq in user_quests.data if uq["status"] == "completed"])
        in_progress_quests = len([uq for uq in user_quests.data if uq["status"] == "in_progress"])
        available_quests_count = supabase.table("quests").select("id", count="exact").eq("is_active", True).execute().count or 0
        
        total_points = sum(uq["quests"]["points"] for uq in user_quests.data if uq["status"] == "completed")
        
        return {
            "total_quests": total_quests,
            "available_quests": available_quests_count - total_quests,
            "completed_quests": completed_quests,
            "in_progress_quests": in_progress_quests,
            "total_points": total_points
        }
    except Exception as e:
        handle_database_error(e, "ã‚¯ã‚¨ã‚¹ãƒˆçµ±è¨ˆã®å–å¾—")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèªç”¨ã®ãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/debug/check-quest-tables")
async def check_quest_tables(
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚¯ã‚¨ã‚¹ãƒˆé–¢é€£ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    try:
        validate_supabase()
        
        result = {}
        
        # questsãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª
        try:
            quests_result = supabase.table("quests").select("count", count="exact").execute()
            result["quests_table"] = {
                "exists": True,
                "count": quests_result.count
            }
        except Exception as e:
            result["quests_table"] = {
                "exists": False,
                "error": str(e)
            }
        
        # user_questsãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª
        try:
            user_quests_result = supabase.table("user_quests").select("count", count="exact").execute()
            result["user_quests_table"] = {
                "exists": True,
                "count": user_quests_result.count
            }
        except Exception as e:
            result["user_quests_table"] = {
                "exists": False,
                "error": str(e)
            }
        
        # quest_submissionsãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª
        try:
            submissions_result = supabase.table("quest_submissions").select("count", count="exact").execute()
            result["quest_submissions_table"] = {
                "exists": True,
                "count": submissions_result.count
            }
        except Exception as e:
            result["quest_submissions_table"] = {
                "exists": False,
                "error": str(e)
            }
        
        return result
        
    except Exception as e:
        return {"error": f"Database connection failed: {str(e)}"}

# =============================================================================
# Conversation Agentæ¤œè¨¼ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =============================================================================

@app.post("/conversation-agent/chat", response_model=ConversationAgentResponse)
async def chat_with_conversation_agent(
    request: ConversationAgentRequest,
    current_user: int = Depends(get_current_user_cached)
):
    """
    å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¤œè¨¼ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
    
    é€šå¸¸ã® /chat ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰åˆ†é›¢ã•ã‚ŒãŸã€conversation_agent ã®æ©Ÿèƒ½ã‚’
    ç‹¬ç«‹ã—ã¦æ¤œè¨¼ã™ã‚‹ãŸã‚ã®å°‚ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚
    
    Features:
    - å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã‚’ç‹¬ç«‹ã—ã¦æ¤œè¨¼å¯èƒ½
    - ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã®è©³ç´°æƒ…å ±å–å¾—
    - ãƒ¢ãƒƒã‚¯/å®Ÿãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆå¯èƒ½
    - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–
    """
    use_optimized = os.environ.get("USE_OPTIMIZED_AGENT", "true").lower() == "true"
    
    if use_optimized:
        result = await optimized_chat_with_conversation_agent(
            request=request,
            current_user=current_user,
            supabase=supabase,
            llm_client=llm_client,
            conversation_orchestrator=conversation_orchestrator,
            CONVERSATION_AGENT_AVAILABLE=CONVERSATION_AGENT_AVAILABLE,
            ENABLE_CONVERSATION_AGENT=ENABLE_CONVERSATION_AGENT
        )
        
        # æ—¢å­˜ã®ConversationAgentResponseãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        return ConversationAgentResponse(
            response=result.response,
            timestamp=result.timestamp,
            support_type=result.support_type,
            selected_acts=result.selected_acts,
            state_snapshot=result.state_snapshot,
            project_plan=result.project_plan,
            decision_metadata=result.decision_metadata,
            metrics=result.metrics,
            debug_info=result.debug_info,
            conversation_id=result.conversation_id,
            history_count=result.history_count,
            error=result.error,
            warning=result.warning
        )
    else:
        # æ—¢å­˜ã®å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        start_time = time.time()

        try:
            validate_supabase()

            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
            if not CONVERSATION_AGENT_AVAILABLE:
                return ConversationAgentResponse(
                    response="å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    support_type="error",
                    selected_acts=[],
                    state_snapshot={},
                    decision_metadata={},
                    metrics={"error": "module_not_available"},
                    error="ConversationAgent module not available",
                    history_count=0
                )

            # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ç”¨æ„
            if conversation_orchestrator is None:
                try:
                    temp_orchestrator = ConversationOrchestrator(
                        llm_client=llm_client,
                        use_mock=request.mock_mode
                    )
                    logger.info(f"âœ… å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸€æ™‚åˆæœŸåŒ–å®Œäº†ï¼ˆmock={request.mock_mode}ï¼‰")
                except Exception as e:
                    logger.error(f"âŒ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                    return ConversationAgentResponse(
                        response="å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
                        timestamp=datetime.now(timezone.utc).isoformat(),
                        support_type="error",
                        selected_acts=[],
                        state_snapshot={},
                        decision_metadata={},
                        metrics={"error": "initialization_failed"},
                        error=f"Initialization error: {str(e)}",
                        history_count=0
                    )
            else:
                temp_orchestrator = conversation_orchestrator

            # ãƒšãƒ¼ã‚¸IDã®æ±ºå®š
            page_id = request.page_id or (f"project-{request.project_id}" if request.project_id else "general")

            # conversationã®å–å¾—ã¾ãŸã¯ä½œæˆ
            conversation_id = await get_or_create_conversation(current_user, page_id)

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®å–å¾—
            project_context = None
            if request.project_id:
                if request.mock_mode:
                    project_context = {
                        "theme": "AIæŠ€è¡“ã®æ•™è‚²ã¸ã®å¿œç”¨",
                        "question": "AIã‚’æ´»ç”¨ã—ãŸå€‹åˆ¥æœ€é©åŒ–å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã®ã‚ˆã†ã«å­¦ç¿’åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ã‹ï¼Ÿ",
                        "hypothesis": "AIãŒå­¦ç¿’è€…ã®ç†è§£åº¦ã¨å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€å€‹åˆ¥ã«æœ€é©åŒ–ã•ã‚ŒãŸå­¦ç¿’çµŒé¨“ã‚’æä¾›ã—ã€å­¦ç¿’åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹",
                        "id": request.project_id
                    }
                    logger.info(f"âœ… ãƒ¢ãƒƒã‚¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ä½¿ç”¨: {project_context['theme']}")
                else:
                    try:
                        project_result = supabase.table('projects').select('*').eq('id', request.project_id).eq('user_id', current_user).execute()
                        if project_result.data:
                            project = project_result.data[0]
                            project_context = {
                                "theme": project.get('theme'),
                                "question": project.get('question'),
                                "hypothesis": project.get('hypothesis'),
                                "id": request.project_id
                            }
                            logger.info(f"âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±å–å¾—æˆåŠŸ: {project['theme']}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±å–å¾—å¤±æ•—: {e}")

            # å¯¾è©±å±¥æ­´ã®å–å¾—
            conversation_history = []
            if request.include_history:
                try:
                    history_response = supabase.table("chat_logs").select(
                        "id, sender, message, created_at, context_data"
                    ).eq(
                        "conversation_id", conversation_id
                    ).order(
                        "created_at", desc=False
                    ).limit(
                        request.history_limit
                    ).execute()

                    if history_response.data:
                        conversation_history = [
                            {"sender": msg["sender"], "message": msg["message"]}
                            for msg in history_response.data
                        ]
                        logger.info(f"ğŸ“œ å¯¾è©±å±¥æ­´å–å¾—: {len(conversation_history)}ä»¶")
                except Exception as e:
                    logger.warning(f"âš ï¸ å¯¾è©±å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

            # å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§å‡¦ç†ï¼ˆå†…å´ã® try/exceptï¼‰
            try:
                agent_start = time.time()

                agent_result = temp_orchestrator.process_turn(
                    user_message=request.message,
                    conversation_history=conversation_history,
                    project_context=project_context,
                    user_id=current_user,
                    conversation_id=conversation_id
                )

                agent_time = time.time() - agent_start

                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®æ§‹ç¯‰
                debug_info = None
                if request.debug_mode:
                    debug_info = {
                        "processing_time_ms": int(agent_time * 1000),
                        "mock_mode": request.mock_mode,
                        "history_items": len(conversation_history),
                        "has_project_context": bool(project_context),
                        "conversation_id": conversation_id,
                        "page_id": page_id,
                        "raw_state": agent_result.get("state_snapshot", {}),
                        "raw_decision": agent_result.get("decision_metadata", {}),
                        "raw_metrics": agent_result.get("metrics", {})
                    }

                # å¿œç­”ã‚’DBä¿å­˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
                user_message_data = {
                    "user_id": current_user,
                    "page": "legacy",  # å»ƒæ­¢äºˆå®š: context_dataã‚’ä½¿ç”¨
                    "sender": "user",
                    "message": request.message,
                    "conversation_id": conversation_id,
                    "context_data": json.dumps({
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "agent_endpoint": True,
                        "project_id": request.project_id,
                        "page_id": page_id  # ãƒšãƒ¼ã‚¸æƒ…å ±ã¯context_dataã«æ ¼ç´
                    }, ensure_ascii=False)
                }
                await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(user_message_data).execute())

                # å¿œç­”ã‚’DBä¿å­˜ï¼ˆAIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
                ai_message_data = {
                    "user_id": current_user,
                    "page": "legacy",  # å»ƒæ­¢äºˆå®š: context_dataã‚’ä½¿ç”¨
                    "sender": "assistant",
                    "message": agent_result["response"],
                    "conversation_id": conversation_id,
                    "context_data": json.dumps({
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "agent_endpoint": True,
                        "page_id": page_id,  # ãƒšãƒ¼ã‚¸æƒ…å ±ã¯context_dataã«æ ¼ç´
                        "support_type": agent_result.get("support_type"),
                        "selected_acts": agent_result.get("selected_acts"),
                        "state_snapshot": agent_result.get("state_snapshot", {}),
                        "project_plan": agent_result.get("project_plan"),
                        "decision_metadata": agent_result.get("decision_metadata", {}),
                        "metrics": agent_result.get("metrics", {})
                    }, ensure_ascii=False)
                }
                await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(ai_message_data).execute())

                # conversation ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ›´æ–°
                await update_conversation_timestamp(conversation_id)

                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹
                return ConversationAgentResponse(
                    response=agent_result["response"],
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    support_type=agent_result.get("support_type", "unknown"),
                    selected_acts=agent_result.get("selected_acts", []),
                    state_snapshot=agent_result.get("state_snapshot", {}),
                    project_plan=agent_result.get("project_plan"),
                    decision_metadata=agent_result.get("decision_metadata", {}),
                    metrics=agent_result.get("metrics", {}),
                    debug_info=debug_info,
                    conversation_id=conversation_id,
                    history_count=len(conversation_history)
                )

            except Exception as e:
                logger.error(f"âŒ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                logger.error(f"Traceback: {traceback.format_exc()}")

                return ConversationAgentResponse(
                    response="ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å¯¾è©±å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    support_type="error",
                    selected_acts=[],
                    state_snapshot={},
                    decision_metadata={},
                    metrics={"error": "processing_failed"},
                    error=f"Processing error: {str(e)}",
                    warning="ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                    conversation_id=conversation_id,
                    history_count=len(conversation_history)
                )

        # â† ã“ã“ã‹ã‚‰ã¯å¤–å´ try ã«å¯¾ã™ã‚‹ except ç¾¤ï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’1æ®µæˆ»ã™ï¼‰
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")

            return ConversationAgentResponse(
                response="ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                timestamp=datetime.now(timezone.utc).isoformat(),
                support_type="error",
                selected_acts=[],
                state_snapshot={},
                decision_metadata={},
                metrics={"error": "system_error", "processing_time_ms": int((time.time() - start_time) * 1000)},
                error=f"System error: {str(e)}",
                history_count=0
            )


@app.get("/conversation-agent/status")
async def get_conversation_agent_status(
    current_user: int = Depends(get_current_user_cached)
):
    """
    å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    Returns:
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¯ç”¨æ€§ã€è¨­å®šã€çŠ¶æ…‹æƒ…å ±
    """
    try:
        status = {
            "available": CONVERSATION_AGENT_AVAILABLE,
            "enabled": ENABLE_CONVERSATION_AGENT,
            "initialized": conversation_orchestrator is not None,
            "module_path": "conversation_agent",
            "environment": {
                "ENABLE_CONVERSATION_AGENT": os.environ.get("ENABLE_CONVERSATION_AGENT", "false"),
                "mode": "mock" if conversation_orchestrator and hasattr(conversation_orchestrator, 'use_mock') else "unknown"
            },
            "features": {
                "state_extraction": True,
                "support_typing": True,
                "policy_engine": True,
                "project_planning": True
            }
        }
        
        # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆã€è¿½åŠ æƒ…å ±ã‚’å–å¾—
        if conversation_orchestrator:
            try:
                status["orchestrator_info"] = {
                    "class": conversation_orchestrator.__class__.__name__,
                    "has_llm_client": conversation_orchestrator.llm_client is not None if hasattr(conversation_orchestrator, 'llm_client') else False,
                    "mock_mode": conversation_orchestrator.use_mock if hasattr(conversation_orchestrator, 'use_mock') else None
                }
            except Exception as e:
                status["orchestrator_info"] = {"error": str(e)}
        
        return status
        
    except Exception as e:
        logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "available": False,
            "error": str(e)
        }

@app.post("/conversation-agent/initialize")
async def initialize_conversation_agent(
    mock_mode: bool = True,
    current_user: int = Depends(get_current_user_cached)
):
    """
    å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ‰‹å‹•åˆæœŸåŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç®¡ç†è€…ç”¨ï¼‰
    
    Args:
        mock_mode: ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–ã™ã‚‹ã‹
    
    Returns:
        åˆæœŸåŒ–çµæœ
    """
    global conversation_orchestrator
    
    try:
        if not CONVERSATION_AGENT_AVAILABLE:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ä¸å¯ã§ã™"
            )
        
        # æ—¢å­˜ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if conversation_orchestrator:
            logger.info("æ—¢å­˜ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
            conversation_orchestrator = None
        
        # æ–°ã—ã„ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
        conversation_orchestrator = ConversationOrchestrator(
            llm_client=llm_client,
            use_mock=mock_mode
        )
        
        logger.info(f"âœ… å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ‰‹å‹•åˆæœŸåŒ–å®Œäº†ï¼ˆmock={mock_mode}ï¼‰")
        
        return {
            "success": True,
            "message": f"å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’{'ãƒ¢ãƒƒã‚¯' if mock_mode else 'å®Ÿ'}ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–ã—ã¾ã—ãŸ",
            "mock_mode": mock_mode,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
        )

# Phase 2: AIææ¡ˆæ©Ÿèƒ½ï¼ˆä»Šå¾Œå®Ÿè£…äºˆå®šï¼‰
# =============================================================================

# ç¾åœ¨ã¯Placeholderå®Ÿè£…ï¼ˆPhase 2ã§å®Ÿè£…ï¼‰
@app.get("/quest-recommendations")
async def get_quest_recommendations(
    current_user: int = Depends(get_current_user_cached)
):
    """AIæ¨è–¦ã‚¯ã‚¨ã‚¹ãƒˆå–å¾—ï¼ˆPhase 2ã§å®Ÿè£…äºˆå®šï¼‰"""
    return {"message": "Phase 2ã§å®Ÿè£…äºˆå®š", "recommendations": []}

@app.post("/generate-quest")
async def generate_quest(
    generation_data: Dict[str, Any],
    current_user: int = Depends(get_current_user_cached)
):
    """AIç”Ÿæˆã‚¯ã‚¨ã‚¹ãƒˆï¼ˆPhase 2ã§å®Ÿè£…äºˆå®šï¼‰"""
    return {"message": "Phase 2ã§å®Ÿè£…äºˆå®š", "quest": None}

# =============================================================================
# ç®¡ç†è€…æ©Ÿèƒ½ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
# =============================================================================

@app.post("/admin/create-test-user")
async def create_test_user(user_data: AdminUserCreate):
    """è² è·ãƒ†ã‚¹ãƒˆç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    try:
        validate_supabase()
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: loadtest_user_* ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿è¨±å¯
        if not user_data.username.startswith("loadtest_user_"):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯ 'loadtest_user_' ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            )
        
        # æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€é©åŒ–ï¼šå¿…è¦æœ€å°é™ã®ã‚¯ã‚¨ãƒªï¼‰
        existing_user = supabase.table("users").select("id").eq("username", user_data.username).execute()
        if existing_user.data:
            return {"message": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_data.username} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™", "id": existing_user.data[0]["id"]}
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        result = supabase.table("users").insert({
            "username": user_data.username,
            "password": user_data.password
        }).execute()
        
        if result.data and len(result.data) > 0:
            user = result.data[0]
            return {
                "message": f"ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_data.username} ã‚’ä½œæˆã—ã¾ã—ãŸ",
                "id": user["id"]
            }
        else:
            raise HTTPException(status_code=500, detail="ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )

@app.delete("/admin/cleanup-test-users")
async def cleanup_test_users():
    """ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸€æ‹¬å‰Šé™¤ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    try:
        validate_supabase()
        
        # loadtest_user_* ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å‰Šé™¤ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        result = supabase.table("users").delete().like("username", "loadtest_user_%").execute()
        
        deleted_count = len(result.data) if result.data else 0
        
        return {
            "message": f"{deleted_count}äººã®ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
        }
        
    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼å‰Šé™¤ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )

# =============================================================================
# ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ  ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =============================================================================

@app.post("/ontology-chat", response_model=OntologyChatResponse)
async def ontology_chat(
    request: OntologyChatRequest,
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚’ç”¨ã„ãŸå¯¾è©±ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆEnhancedOrchestratorV2ä½¿ç”¨ï¼‰"""
    start_time = time.time()
    
    try:
        validate_supabase()
        
        if not ONTOLOGY_GRAPH_AVAILABLE or not enhanced_orchestrator or not inference_logger:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ï¼ˆEnhancedOrchestratorV2ï¼‰ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        # ä¼šè©±IDã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
        conversation_id = await get_or_create_global_chat_session(current_user)
        
        # ä¼šè©±å±¥æ­´ã‚’å–å¾—
        conversation_history = []
        try:
            recent_messages = await asyncio.to_thread(
                lambda: supabase.table("chat_logs")
                .select("sender, message")
                .eq("conversation_id", conversation_id)
                .order("created_at", desc=False)
                .limit(20)
                .execute()
            )
            
            for msg in recent_messages.data:
                role = "user" if msg["sender"] == "user" else "assistant"
                conversation_history.append({
                    "role": role,
                    "content": msg["message"]
                })
        except Exception as e:
            logger.error(f"ä¼šè©±å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ä¼šè©±ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§æŒ¨æ‹¶åˆ¤å®š
        logger.info(f"ğŸ” ä¼šè©±ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çŠ¶æ…‹: {conversation_filter is not None}")
        if conversation_filter:
            logger.info(f"ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¯¾è±¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: '{request.message}'")
            should_skip, greeting_response, filter_reason = conversation_filter.filter_message(
                request.message, 
                user_id=str(current_user)
            )
            logger.info(f"ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ: skip={should_skip}, reason={filter_reason}")
            
            if should_skip and greeting_response:
                # æŒ¨æ‹¶ã¨ã—ã¦å‡¦ç†ï¼ˆã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ç…§åˆã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                logger.info(f"ğŸ¤ æŒ¨æ‹¶ã¨ã—ã¦å‡¦ç†: filter_reason={filter_reason}")
                
                # ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜ï¼ˆæŒ¨æ‹¶ï¼‰
                user_message_data = {
                    "user_id": current_user,
                    "page": "ontology",
                    "sender": "user",
                    "message": request.message,
                    "conversation_id": conversation_id,
                    "context_data": json.dumps({
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "filter_reason": filter_reason,
                        "skipped_ontology": True
                    })
                }
                await asyncio.to_thread(
                    lambda: supabase.table("chat_logs").insert(user_message_data).execute()
                )
                
                assistant_message_data = {
                    "user_id": current_user,
                    "page": "ontology",
                    "sender": "ai",
                    "message": greeting_response,
                    "conversation_id": conversation_id,
                    "context_data": json.dumps({
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "response_type": "greeting",
                        "filter_reason": filter_reason
                    })
                }
                await asyncio.to_thread(
                    lambda: supabase.table("chat_logs").insert(assistant_message_data).execute()
                )
                
                # æŒ¨æ‹¶å¿œç­”ã‚’è¿”ã™
                return OntologyChatResponse(
                    response=greeting_response,
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    support_type="GREETING",
                    selected_acts=["GREET"],
                    current_node=None,
                    next_suggestions=[],
                    graph_context={
                        "filter_reason": filter_reason,
                        "skipped_ontology": True
                    },
                    processing_time_ms=int((time.time() - start_time) * 1000),
                    success=True
                )
        
        # æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é–‹å§‹
        trace_id = None
        if request.include_inference_log:
            trace_id = inference_logger.start_inference_trace(
                user_id=str(current_user),
                conversation_id=conversation_id,
                user_message=request.message
            )
        
        try:
            # EnhancedOrchestratorV2ã§å¯¾è©±å‡¦ç†ã‚’å®Ÿè¡Œ
            logger.info(f"ğŸš€ EnhancedOrchestratorV2ã«ã‚ˆã‚‹å¯¾è©±å‡¦ç†é–‹å§‹: user_id={current_user}")
            
            result = enhanced_orchestrator.process_turn(
                user_message=request.message,
                conversation_history=conversation_history,
                project_context=None,
                user_id=current_user,
                conversation_id=conversation_id,
                session_context={"trace_id": trace_id}
            )
            
            logger.info(f"âœ… EnhancedOrchestratorV2å¯¾è©±å‡¦ç†å®Œäº†")
            
            # çµæœã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡º
            response_text = result.get("natural_reply", "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€å¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            support_type = result.get("support_type", "PATHFINDING")
            selected_acts = result.get("acts", ["INFORM"])
            current_node = result.get("current_node")
            
            # ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã¨ãã®ä»–ã®æƒ…å ±ã‚’çµæœã‹ã‚‰å–å¾—
            graph_context = result.get("graph_context", {})
            suggestions = result.get("next_suggestions", [])
            followups = result.get("followups", [])
            
            # ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜
            user_message_data = {
                "user_id": current_user,
                "page": "ontology",
                "sender": "user",
                "message": request.message,
                "conversation_id": conversation_id,
                "context_data": json.dumps({
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "ontology_mode": True,
                    "trace_id": trace_id
                }, ensure_ascii=False)
            }
            await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(user_message_data).execute())
            
            ai_message_data = {
                "user_id": current_user,
                "page": "ontology",
                "sender": "assistant",
                "message": response_text,
                "conversation_id": conversation_id,
                "context_data": json.dumps({
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "ontology_mode": True,
                    "support_type": support_type,
                    "selected_acts": selected_acts,
                    "trace_id": trace_id
                }, ensure_ascii=False)
            }
            await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(ai_message_data).execute())
            
            # æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å®Œäº†
            processing_time = int((time.time() - start_time) * 1000)
            if request.include_inference_log:
                inference_logger.complete_inference_trace(
                    final_response=response_text,
                    graph_state_before={},
                    graph_state_after=graph_context,
                    success=True
                )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ§‹ç¯‰
            return OntologyChatResponse(
                response=response_text,
                timestamp=datetime.now(timezone.utc).isoformat(),
                graph_context=graph_context,
                current_node=current_node,
                next_suggestions=suggestions,
                inference_trace_id=trace_id,
                inference_steps=[step.to_dict() for step in inference_logger.current_trace.steps] if inference_logger.current_trace else [],
                support_type=support_type,
                selected_acts=selected_acts,
                processing_time_ms=processing_time,
                success=True
            )
            
        except Exception as e:
            logger.error(f"âŒ EnhancedOrchestratorV2å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            
            # æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚¨ãƒ©ãƒ¼ã‚’è¨˜éŒ²
            if request.include_inference_log and inference_logger:
                inference_logger.complete_inference_trace(
                    final_response="",
                    graph_state_before={},
                    graph_state_after={},
                    success=False,
                    error_message=str(e)
                )
            raise e
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼å¯¾è©±ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        processing_time = int((time.time() - start_time) * 1000)
        return OntologyChatResponse(
            response="ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
            timestamp=datetime.now(timezone.utc).isoformat(),
            processing_time_ms=processing_time,
            success=False,
            error_message=str(e)
        )


@app.get("/ontology-graph/{user_id}", response_model=GraphStateResponse)
async def get_ontology_graph_state(
    user_id: int,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã‚’å–å¾—"""
    try:
        validate_supabase()
        
        if user_id != current_user:
            raise HTTPException(status_code=403, detail="ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
        
        if not ONTOLOGY_GRAPH_AVAILABLE or not ontology_adapter:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        user_id_str = str(user_id)
        
        # ã‚°ãƒ©ãƒ•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€åº¦ã ã‘å–å¾—
        graph_context = ontology_adapter.get_graph_context(user_id_str)
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç¾åœ¨ã®ãƒãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
        current_node_dict = graph_context.get("current_node")
        current_node_response = NodeResponse(**current_node_dict) if current_node_dict else None

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨ãƒãƒ¼ãƒ‰ã‚’æ§‹ç¯‰
        user_nodes = [n for n in ontology_adapter.graph.nodes.values() if n.student_id == user_id_str]
        user_node_ids = {n.id for n in user_nodes}
        nodes_response = [NodeResponse(
            id=node.id, type=node.type.value, text=node.text, student_id=node.student_id,
            timestamp=node.timestamp.isoformat(), state=node.state, confidence=node.confidence,
            clarity=node.clarity, depth=node.depth, alignment_goal=node.alignment_goal,
            tags=node.tags, metadata=node.metadata
        ) for node in user_nodes]

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨ã‚¨ãƒƒã‚¸ã‚’æ§‹ç¯‰
        user_edges = [e for e in ontology_adapter.graph.edges if e.src in user_node_ids and e.dst in user_node_ids]
        edges_response = [EdgeResponse(
            src=edge.src, rel=edge.rel.value, dst=edge.dst,
            confidence=edge.confidence, timestamp=edge.timestamp.isoformat(),
            metadata=edge.metadata
        ) for edge in user_edges]
        
        # çµ±è¨ˆæƒ…å ±ã‚’æ§‹ç¯‰
        statistics = {
            "node_count": len(nodes_response),
            "edge_count": len(edges_response),
            "cycles_completed": graph_context.get("cycles_completed", 0)
        }

        return GraphStateResponse(
            user_id=user_id_str,
            current_node=current_node_response,
            progress=graph_context.get("progress", {}),
            suggestions=graph_context.get("suggestions", []),
            nodes=nodes_response,
            edges=edges_response,
            statistics=statistics
        )

    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã®å–å¾—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã®å–å¾—ä¸­ã«ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )
        
        # ã‚¨ãƒƒã‚¸ä¸€è¦§ã‚’æ§‹ç¯‰
        user_edges = [edge for edge in ontology_adapter.graph.edges 
                      if edge.src in [node.id for node in user_nodes]]
        
        edges_response = [EdgeResponse(
            src=edge.src,
            rel=edge.rel.value,
            dst=edge.dst,
            confidence=edge.confidence,
            timestamp=edge.timestamp.isoformat(),
            metadata=edge.metadata
        ) for edge in user_edges]
        
        # çµ±è¨ˆæƒ…å ±
        statistics = {
            "total_nodes": len(user_nodes),
            "total_edges": len(user_edges),
            "node_types": list(set(node.type.value for node in user_nodes)),
            "avg_confidence": sum(node.confidence for node in user_nodes) / len(user_nodes) if user_nodes else 0,
            "avg_clarity": sum(node.clarity for node in user_nodes) / len(user_nodes) if user_nodes else 0
        }
        
        return GraphStateResponse(
            user_id=str(user_id),
            current_node=NodeResponse(**graph_context["current_node"]) if graph_context.get("current_node") else None,
            progress=graph_context.get("progress", {}),
            suggestions=graph_context.get("suggestions", []),
            nodes=nodes_response,
            edges=edges_response,
            statistics=statistics
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ã‚°ãƒ©ãƒ•çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ã‚°ãƒ©ãƒ•çŠ¶æ…‹ã®å–å¾—")


@app.post("/ontology-nodes", response_model=NodeResponse)
async def create_ontology_node(
    request: NodeCreateRequest,
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    try:
        validate_supabase()
        
        if not ONTOLOGY_GRAPH_AVAILABLE or not ontology_adapter:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        # ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’æ¤œè¨¼
        try:
            node_type = NodeType(request.type)
        except ValueError:
            raise HTTPException(
                status_code=400,
                detail=f"ç„¡åŠ¹ãªãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: {request.type}"
            )
        
        # ãƒãƒ¼ãƒ‰ã‚’ä½œæˆ
        node = Node(
            id=f"{request.type.lower()}_{datetime.now().strftime('%Y%m%d%H%M%S')}_{current_user}",
            type=node_type,
            text=request.text,
            student_id=str(current_user),
            timestamp=datetime.now(),
            clarity=request.clarity,
            depth=request.depth,
            alignment_goal=request.alignment_goal,
            tags=request.tags
        )
        
        # ã‚°ãƒ©ãƒ•ã«è¿½åŠ 
        success = ontology_adapter.graph.add_node(node)
        if not success:
            raise HTTPException(
                status_code=400,
                detail="ãƒãƒ¼ãƒ‰ã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆIDé‡è¤‡ã®å¯èƒ½æ€§ï¼‰"
            )
        
        return NodeResponse(
            id=node.id,
            type=node.type.value,
            text=node.text,
            student_id=node.student_id,
            timestamp=node.timestamp.isoformat(),
            state=node.state,
            confidence=node.confidence,
            clarity=node.clarity,
            depth=node.depth,
            alignment_goal=node.alignment_goal,
            tags=node.tags,
            metadata=node.metadata
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ãƒãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ãƒãƒ¼ãƒ‰ã®ä½œæˆ")


@app.post("/ontology-edges", response_model=EdgeResponse)
async def create_ontology_edge(
    request: EdgeCreateRequest,
    current_user: int = Depends(get_current_user_cached)
):
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚¨ãƒƒã‚¸ã‚’ä½œæˆ"""
    try:
        validate_supabase()
        
        if not ONTOLOGY_GRAPH_AVAILABLE or not ontology_adapter:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        # é–¢ä¿‚ã‚¿ã‚¤ãƒ—ã‚’æ¤œè¨¼
        try:
            relation_type = RelationType(request.relation_type)
        except ValueError:
            raise HTTPException(
                status_code=400,
                detail=f"ç„¡åŠ¹ãªé–¢ä¿‚ã‚¿ã‚¤ãƒ—: {request.relation_type}"
            )
        
        # ãƒãƒ¼ãƒ‰ã®å­˜åœ¨ç¢ºèª
        if request.src_node_id not in ontology_adapter.graph.nodes:
            raise HTTPException(
                status_code=404,
                detail=f"ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {request.src_node_id}"
            )
        
        if request.dst_node_id not in ontology_adapter.graph.nodes:
            raise HTTPException(
                status_code=404,
                detail=f"å®›å…ˆãƒãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {request.dst_node_id}"
            )
        
        # ã‚¨ãƒƒã‚¸ã‚’ä½œæˆ
        edge = Edge(
            src=request.src_node_id,
            rel=relation_type,
            dst=request.dst_node_id,
            confidence=request.confidence,
            timestamp=datetime.now()
        )
        
        # ã‚°ãƒ©ãƒ•ã«è¿½åŠ ï¼ˆåˆ¶ç´„ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        success = ontology_adapter.graph.add_edge(edge)
        if not success:
            raise HTTPException(
                status_code=400,
                detail="ã‚¨ãƒƒã‚¸ã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆåˆ¶ç´„é•åã®å¯èƒ½æ€§ï¼‰"
            )
        
        return EdgeResponse(
            src=edge.src,
            rel=edge.rel.value,
            dst=edge.dst,
            confidence=edge.confidence,
            timestamp=edge.timestamp.isoformat(),
            metadata=edge.metadata
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ã‚¨ãƒƒã‚¸ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ã‚¨ãƒƒã‚¸ã®ä½œæˆ")


@app.get("/ontology-inference/{trace_id}", response_model=InferenceTraceResponse)
async def get_inference_trace(
    trace_id: str,
    current_user: int = Depends(get_current_user_cached)
):
    """æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—"""
    try:
        if not ONTOLOGY_GRAPH_AVAILABLE or not inference_logger:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="æ¨è«–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        trace = inference_logger.get_trace(trace_id)
        if not trace:
            raise HTTPException(status_code=404, detail="æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãƒã‚§ãƒƒã‚¯
        if trace.user_id != str(current_user):
            raise HTTPException(status_code=403, detail="ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
        
        return InferenceTraceResponse(**trace.to_dict())
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã®å–å¾—")


@app.get("/ontology-inference/{trace_id}/visualization", response_model=InferenceVisualizationResponse)
async def get_inference_visualization(
    trace_id: str,
    current_user: int = Depends(get_current_user_cached)
):
    """æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã®å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        if not ONTOLOGY_GRAPH_AVAILABLE or not inference_logger:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="æ¨è«–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        visualization_data = inference_logger.get_trace_visualization_data(trace_id)
        if not visualization_data:
            raise HTTPException(status_code=404, detail="æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãƒã‚§ãƒƒã‚¯
        trace_info = visualization_data.get("trace_info", {})
        if trace_info.get("user_id") != str(current_user):
            raise HTTPException(status_code=403, detail="ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
        
        return InferenceVisualizationResponse(**visualization_data)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ¨è«–å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "æ¨è«–å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã®å–å¾—")


@app.get("/ontology-inference/user/{user_id}/traces")
async def get_user_inference_traces(
    user_id: int,
    limit: int = 10,
    current_user: int = Depends(get_current_user_cached)
):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—"""
    try:
        # ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãƒã‚§ãƒƒã‚¯
        if user_id != current_user:
            raise HTTPException(status_code=403, detail="ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
        
        if not ONTOLOGY_GRAPH_AVAILABLE or not inference_logger:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="æ¨è«–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        traces = inference_logger.get_user_traces(str(user_id), limit)
        
        return {
            "user_id": user_id,
            "traces": [trace.to_dict() for trace in traces],
            "total_count": len(traces)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã®å–å¾—")


@app.get("/ontology-inference/statistics")
async def get_inference_statistics(
    current_user: int = Depends(get_current_user_cached)
):
    """æ¨è«–ã‚·ã‚¹ãƒ†ãƒ ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        if not ONTOLOGY_GRAPH_AVAILABLE or not inference_logger:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="æ¨è«–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            )
        
        statistics = inference_logger.get_system_statistics()
        
        return {
            "system_statistics": statistics,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ¨è«–çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        handle_database_error(e, "æ¨è«–çµ±è¨ˆã®å–å¾—")



@app.get("/ontology-status")
async def get_ontology_system_status():
    """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®ç¨¼åƒçŠ¶æ³ã‚’ç¢ºèª"""
    return {
        "ontology_graph_available": ONTOLOGY_GRAPH_AVAILABLE,
        "ontology_adapter_initialized": ontology_adapter is not None,
        "inference_logger_initialized": inference_logger is not None,
        "test_page_url": "/ontology-test",
        "api_endpoints": {
            "chat": "/ontology-chat",
            "graph_state": "/ontology-graph/{user_id}",
            "create_node": "/ontology-nodes",
            "create_edge": "/ontology-edges",
            "inference_trace": "/ontology-inference/{trace_id}",
            "inference_visualization": "/ontology-inference/{trace_id}/visualization",
            "user_traces": "/ontology-inference/user/{user_id}/traces",
            "statistics": "/ontology-inference/statistics"
        },
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


# =============================================
# Phase 1: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»ç›£è¦–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =============================================

@app.get("/metrics/llm-system")
async def get_llm_system_metrics(
    current_user: int = Depends(get_current_user_cached)
):
    """Phase 1 LLMã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
    try:
        if PHASE1_AVAILABLE and phase1_llm_manager and phase1_llm_manager._initialized:
            metrics = phase1_llm_manager.get_metrics()
            health = phase1_llm_manager.health_check()
            
            return {
                "phase1_system": {
                    "metrics": metrics,
                    "health": health,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                },
                "legacy_system": {
                    "available": llm_client is not None,
                    "class": llm_client.__class__.__name__ if llm_client else None
                }
            }
        else:
            return {
                "phase1_system": {
                    "status": "not_initialized" if PHASE1_AVAILABLE else "not_available",
                    "message": "Phase 1ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“" if PHASE1_AVAILABLE else "Phase 1ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ä¸å¯ã§ã™"
                },
                "legacy_system": {
                    "available": llm_client is not None,
                    "status": "active",
                    "message": "æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã¿å‹•ä½œä¸­"
                }
            }
            
    except Exception as e:
        logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "error": str(e),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

@app.get("/debug/llm-system")
async def debug_llm_system(
    current_user: int = Depends(get_current_user_cached)
):
    """Phase 1 LLMã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±"""
    debug_info = {
        "environment_variables": {
            "ENABLE_LLM_POOL": os.environ.get("ENABLE_LLM_POOL", "false"),
            "LLM_POOL_SIZE": os.environ.get("LLM_POOL_SIZE", "5"),
            "LLM_POOL_TIMEOUT": os.environ.get("LLM_POOL_TIMEOUT", "30.0"),
            "LLM_AUTO_FALLBACK": os.environ.get("LLM_AUTO_FALLBACK", "true"),
            "LLM_POOL_DEBUG": os.environ.get("LLM_POOL_DEBUG", "false")
        },
        "system_status": {
            "phase1_available": PHASE1_AVAILABLE,
            "phase1_manager_exists": phase1_llm_manager is not None,
            "phase1_initialized": phase1_llm_manager._initialized if phase1_llm_manager else False,
            "legacy_client_exists": llm_client is not None,
            "current_time": datetime.now(timezone.utc).isoformat()
        }
    }
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æƒ…å ±ã‚’è¿½åŠ 
    if PHASE1_AVAILABLE and phase1_llm_manager and phase1_llm_manager._initialized:
        try:
            debug_info["detailed_metrics"] = phase1_llm_manager.get_metrics()
            debug_info["health_check"] = phase1_llm_manager.health_check()
        except Exception as e:
            debug_info["metrics_error"] = str(e)
    
    return debug_info

@app.post("/admin/llm-system/log-status")
async def log_llm_system_status(
    current_user: int = Depends(get_current_user_cached)
):
    """LLMã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ï¼ˆç®¡ç†è€…ç”¨ï¼‰"""
    try:
        if PHASE1_AVAILABLE:
            log_system_status()
            return {
                "message": "Phase 1ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã—ã¾ã—ãŸ",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        else:
            logger.info("ğŸ“Š LLMã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: Phase 1ã¯åˆ©ç”¨ä¸å¯ã€æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã¿å‹•ä½œä¸­")
            return {
                "message": "Phase 1ã¯åˆ©ç”¨ä¸å¯ã€æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã¿å‹•ä½œä¸­",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
    except Exception as e:
        logger.error(f"ãƒ­ã‚°å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "error": str(e),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

if __name__ == "__main__":
    # æœ¬ç•ªç’°å¢ƒç”¨ã®è¨­å®š
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        workers=4,  # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹æ•°ã‚’å¢—ã‚„ã™
        access_log=False,  # ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ã‚’ç„¡åŠ¹åŒ–ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
        log_level="warning"  # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã‚‹
    ) 
