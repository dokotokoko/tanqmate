"""
å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµ±åˆåˆ¶å¾¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆPhase 1: ãƒ¢ãƒƒã‚¯ç‰ˆï¼‰
ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ã¦å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚’åˆ¶å¾¡
"""
import json
import logging
import sys
import os
from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime
from .schema import (
    StateSnapshot,
    TurnDecision,
    TurnPackage,
    SupportType,
    SpeechAct,
    ConversationMetrics,
    ProjectPlan
)
from .state_extractor import StateExtractor
from .support_typer import SupportTyper
from .policies import PolicyEngine
from .project_planner import ProjectPlanner

# prompt.pyã¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
from prompt.prompt import generate_response_prompt

logger = logging.getLogger(__name__)

class ConversationOrchestrator:
    """å¯¾è©±ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’çµ±åˆåˆ¶å¾¡"""
    
    # <summary>å¯¾è©±ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚</summary>
    # <arg name="llm_client">LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆæ—¢å­˜ã®module.llm_apiã‚’ä½¿ç”¨ï¼‰ã€‚</arg>
    # <arg name="use_mock">ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã™ã‚‹ã‹ï¼ˆPhase 1ã§ã¯Trueï¼‰ã€‚</arg>
    def __init__(self, llm_client=None, use_mock: bool = False):
        self.llm_client = llm_client
        self.use_mock = use_mock
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.state_extractor = StateExtractor(llm_client)
        self.project_planner = ProjectPlanner(llm_client)
        self.support_typer = SupportTyper(llm_client)
        self.policy_engine = PolicyEngine()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡
        self.metrics = ConversationMetrics()
        
        # ä¼šè©±å±¥æ­´ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        self.conversation_history: List[Dict[str, Any]] = []
        self.support_type_history: List[str] = []
        self.act_history: List[List[str]] = []
    
    # <summary>1ã‚¿ãƒ¼ãƒ³ã®å¯¾è©±å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆï¼‰ã€‚</summary>
    # <arg name="user_message">ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚</arg>
    # <arg name="conversation_history">ä¼šè©±å±¥æ­´ã€‚</arg>
    # <arg name="project_context">ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="user_id">ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="conversation_id">ä¼šè©±IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <returns>å¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆresponse, followups, support_type, selected_acts, state_snapshot, project_plan, decision_metadata, metricsï¼‰ã€‚</returns>
    def process_turn(
        self,
        user_message: str,
        conversation_history: List[Dict[str, str]],
        project_context: Optional[Dict[str, Any]] = None,
        user_id: Optional[int] = None,
        conversation_id: Optional[str] = None
    ) -> Dict[str, Any]:
        
        logger.info("ğŸš€ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†é–‹å§‹")
        logger.info(f"   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message[:100]}...")
        logger.info(f"   - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {bool(project_context)}")
        logger.info(f"   - å±¥æ­´ä»¶æ•°: {len(conversation_history)}")
        
        try:
            # 1. çŠ¶æ…‹æŠ½å‡º(ç†è§£)
            logger.info("ğŸ“Š Step 1: çŠ¶æ…‹æŠ½å‡ºé–‹å§‹")
            state = self._extract_state(conversation_history, project_context, user_id, conversation_id)
            logger.info(f"âœ… Step 1å®Œäº†: ç›®æ¨™={state.goal or 'æœªè¨­å®š'}, ç›®çš„={state.purpose or 'æœªè¨­å®š'}")
            
            # 2. è¨ˆç”»æ€è€ƒãƒ•ã‚§ãƒ¼ã‚ºï¼ˆæ€è€ƒï¼‰
            logger.info("ğŸ¯ Step 2: è¨ˆç”»æ€è€ƒãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹")
            project_plan = self._generate_project_plan(state, conversation_history)
            if project_plan:
                logger.info(f"âœ… Step 2å®Œäº†: åŒ—æ¥µæ˜Ÿ={project_plan.north_star[:50]}...")
            else:
                logger.info("âš ï¸ Step 2å®Œäº†: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ãªã—")
            
            # 3. æ”¯æ´ã‚¿ã‚¤ãƒ—åˆ¤å®š
            logger.info("ğŸ” Step 3: æ”¯æ´ã‚¿ã‚¤ãƒ—åˆ¤å®šé–‹å§‹")
            support_type, support_reason, confidence = self._determine_support_type(state)
            logger.info(f"âœ… Step 3å®Œäº†: æ”¯æ´ã‚¿ã‚¤ãƒ—={support_type}, ç¢ºä¿¡åº¦={confidence}")
            
            # 4. ç™ºè©±ã‚¢ã‚¯ãƒˆé¸æŠ
            logger.info("ğŸ’¬ Step 4: ç™ºè©±ã‚¢ã‚¯ãƒˆé¸æŠé–‹å§‹")
            selected_acts, act_reason = self._select_acts(state, support_type)
            logger.info(f"âœ… Step 4å®Œäº†: ã‚¢ã‚¯ãƒˆ={selected_acts}")
            
            # 5. å¿œç­”ç”Ÿæˆ
            logger.info("ğŸ“ Step 5: å¿œç­”ç”Ÿæˆé–‹å§‹")
            response_package = self._generate_llm_response(
                state, support_type, selected_acts, user_message
            )
            logger.info(f"âœ… Step 5å®Œäº†: å¿œç­”æ–‡å­—æ•°={len(response_package.natural_reply)}")
            
            # 6. ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self._update_metrics(state, support_type, selected_acts)
            
            # 7. å±¥æ­´æ›´æ–°
            self._update_history(support_type, selected_acts, response_package)
            
            # çµæœã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
            result = {
                "response": response_package.natural_reply,
                "followups": response_package.followups,
                "support_type": support_type,
                "selected_acts": selected_acts,
                "state_snapshot": state.dict(exclude={'user_id', 'conversation_id', 'turn_index'}),
                "project_plan": project_plan.dict() if project_plan else None,  # NEW!
                "decision_metadata": {
                    "support_reason": support_reason,
                    "support_confidence": confidence,
                    "act_reason": act_reason,
                    "timestamp": datetime.now().isoformat()
                },
                "metrics": self.metrics.dict()
            }
            
            logger.info("ğŸ‰ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†å®Œäº†")
            return result
            
        except Exception as e:
            import traceback
            logger.error(f"âŒ å¯¾è©±å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(f"âŒ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
            return self._generate_fallback_response(str(e))
    
    # <summary>ä¼šè©±å±¥æ­´ã‹ã‚‰ç¾åœ¨ã®çŠ¶æ…‹ã‚’æŠ½å‡ºã—ã¾ã™ã€‚</summary>
    # <arg name="conversation_history">ä¼šè©±å±¥æ­´ã€‚</arg>
    # <arg name="project_context">ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="user_id">ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="conversation_id">ä¼šè©±IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <returns>ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</returns>
    def _extract_state(
        self,
        conversation_history: List[Dict[str, str]],
        project_context: Optional[Dict[str, Any]],
        user_id: Optional[int],
        conversation_id: Optional[str]
    ) -> StateSnapshot:
        """çŠ¶æ…‹æŠ½å‡ºãƒ•ã‚§ãƒ¼ã‚ºï¼ˆä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ï¼‰"""
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¯ä½¿ç”¨ã—ãªã„ï¼ˆä¼šè©±å±¥æ­´ã‹ã‚‰æ¨æ¸¬ï¼‰
        logger.info("ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹æŠ½å‡ºã‚’é–‹å§‹")
        
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯å‡¦ç†ã‚’ä½¿ç”¨
        use_llm = not self.use_mock and self.llm_client is not None
        
        state = self.state_extractor.extract_from_history(
            conversation_history,
            None,  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¯æ¸¡ã•ãªã„
            use_llm=use_llm,
            mock_mode=True  # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«é™å®šï¼ˆã‚´ãƒ¼ãƒ«ã€ç›®çš„ã€ProjectContextã€ä¼šè©±å±¥æ­´ï¼‰
        )
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¿½åŠ 
        state.user_id = user_id
        state.conversation_id = conversation_id
        state.turn_index = len(conversation_history)
        
        # ä¼šè©±å±¥æ­´ã‹ã‚‰ç›®æ¨™ã‚’æ¨æ¸¬ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        if not state.goal and conversation_history:
            # æœ€åˆã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ç›®æ¨™ã‚’æ¨æ¸¬
            for msg in conversation_history:
                if msg.get('sender') == 'user':
                    state.goal = msg['message'][:100]  # æœ€åˆã®100æ–‡å­—ã‚’æš«å®šçš„ãªç›®æ¨™ã¨ã™ã‚‹
                    break
        
        logger.info(f"çŠ¶æ…‹æŠ½å‡ºå®Œäº†: goal={state.goal}, blockers={len(state.blockers)}")
        
        return state
    
    # <summary>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="conversation_history">ä¼šè©±å±¥æ­´ã€‚</arg>
    # <returns>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ï¼ˆä»»æ„ï¼‰ã€‚</returns>
    def _generate_project_plan(
        self,
        state: StateSnapshot,
        conversation_history: List[Dict[str, str]]
    ) -> Optional[ProjectPlan]:
        
        # ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§ã¯è¨ˆç”»æ€è€ƒã‚’ã‚¹ã‚­ãƒƒãƒ—
        logger.info("ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚ã€è¨ˆç”»æ€è€ƒãƒ•ã‚§ãƒ¼ã‚ºã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return None
        
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹å‡¦ç†ã‚’ä½¿ç”¨
        use_llm = not self.use_mock and self.llm_client is not None
        
        try:
            project_plan = self.project_planner.generate_project_plan(
                state,
                conversation_history,
                use_llm=use_llm
            )
            
            logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ç”Ÿæˆå®Œäº†: åŒ—æ¥µæ˜Ÿ={project_plan.north_star[:50]}...")
            logger.info(f"æ¬¡ã®è¡Œå‹•æ•°: {len(project_plan.next_actions)}, ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³æ•°: {len(project_plan.milestones)}")
            
            return project_plan
            
        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    # <summary>çŠ¶æ…‹ã‹ã‚‰æ”¯æ´ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <returns>(support_type, reason, confidence)ã€‚æ”¯æ´ã‚¿ã‚¤ãƒ—ã€ç†ç”±ã€ç¢ºä¿¡åº¦ã€‚</returns>
    def _determine_support_type(self, state: StateSnapshot) -> Tuple[str, str, float]:
        
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹å‡¦ç†ã‚’ä½¿ç”¨
        use_llm = not self.use_mock and self.llm_client is not None
        
        support_type, reason, confidence = self.support_typer.determine_support_type(
            state,
            use_llm=use_llm
        )
        
        # æ–‡è„ˆã«åŸºã¥ãèª¿æ•´
        if self.support_type_history:
            effectiveness_scores = {}  # Phase 2ã§å®Ÿè£…
            support_type = self.support_typer.adjust_for_context(
                support_type,
                self.support_type_history[-5:],
                effectiveness_scores
            )
        
        logger.info(f"æ”¯æ´ã‚¿ã‚¤ãƒ—åˆ¤å®š: {support_type} (ç¢ºä¿¡åº¦: {confidence:.2f})")
        
        return support_type, reason, confidence
    
    # <summary>æ”¯æ´ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ç™ºè©±ã‚¢ã‚¯ãƒˆã‚’é¸æŠã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <returns>(selected_acts, reason)ã€‚é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã¨ç†ç”±ã€‚</returns>
    def _select_acts(self, state: StateSnapshot, support_type: str) -> Tuple[List[str], str]:
        
        selected_acts, reason = self.policy_engine.select_acts(
            state,
            support_type,
            max_acts=2
        )
        
        # Socraticå„ªå…ˆé †ä½ã§ä¸¦ã³æ›¿ãˆ
        selected_acts = self.policy_engine.get_socratic_priority(selected_acts)
        
        logger.info(f"ç™ºè©±ã‚¢ã‚¯ãƒˆé¸æŠ: {selected_acts}")
        
        return selected_acts, reason

    def _generate_response(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str],
        user_message: str
    ) -> TurnPackage:
        
        if self.use_mock or not self.llm_client:
            return self._generate_llm_response(state, support_type, selected_acts)

        return self._generate_llm_response(state, support_type, selected_acts, user_message)
    
    def _generate_mock_response(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str]
    ) -> TurnPackage:
        
        # ã‚¢ã‚¯ãƒˆã«åŸºã¥ããƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¿œç­”
        responses = {
            SpeechAct.CLARIFY: "ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã©ã®ã‚ˆã†ãªç‚¹ã§å›°ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            SpeechAct.INFORM: "ã“ã®åˆ†é‡ã§ã¯ã€ã¾ãšåŸºæœ¬çš„ãªæ¦‚å¿µã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚",
            SpeechAct.PROBE: "ãªãœãã‚ŒãŒé‡è¦ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿã©ã®ã‚ˆã†ãªæˆæœã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            SpeechAct.ACT: "ã¾ãšã¯30åˆ†ã§ã€å…·ä½“çš„ãªä¾‹ã‚’3ã¤æ›¸ãå‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚",
            SpeechAct.REFRAME: "åˆ¥ã®è§’åº¦ã‹ã‚‰è¦‹ã‚‹ã¨ã€ã“ã‚Œã¯å­¦ç¿’ã®æ©Ÿä¼šã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚",
            SpeechAct.OUTLINE: "ã“ã‚Œã‚’3ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†ã‘ã¦ã¿ã¾ã—ã‚‡ã†ï¼š1) èª¿æŸ»ã€2) å®Ÿé¨“ã€3) æŒ¯ã‚Šè¿”ã‚Šã€‚",
            SpeechAct.DECIDE: "ã©ã®é¸æŠè‚¢ãŒæœ€ã‚‚ç›®æ¨™ã«è¿‘ã¥ã‘ãã†ã§ã™ã‹ï¼ŸåŸºæº–ã‚’æ˜ç¢ºã«ã—ã¾ã—ã‚‡ã†ã€‚",
            SpeechAct.REFLECT: "ã“ã“ã¾ã§ã®è©±ã‚’ã¾ã¨ã‚ã‚‹ã¨ã€ä¸»ãªèª²é¡Œã¯æ˜ç¢ºã«ãªã£ã¦ãã¾ã—ãŸã­ã€‚"
        }
        
        # é¸æŠã•ã‚ŒãŸã‚¢ã‚¯ãƒˆã«åŸºã¥ã„ã¦å¿œç­”ã‚’æ§‹ç¯‰
        response_parts = []
        for act in selected_acts[:2]:
            if act in responses:
                response_parts.append(responses[act])
        
        natural_reply = " ".join(response_parts) if response_parts else "ã©ã®ã‚ˆã†ãªã“ã¨ã§ãŠå›°ã‚Šã§ã™ã‹ï¼Ÿ"
        
        # ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—å€™è£œ
        followups = [
            "å…·ä½“ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "ä»–ã®æ–¹æ³•ã‚‚æ¤œè¨ã—ã¾ã—ã‚‡ã†",
            "ã¾ãšã¯å°ã•ãå§‹ã‚ã¦ã¿ã¾ã™"
        ]
        
        return TurnPackage(
            natural_reply=natural_reply,
            followups=followups[:3],
            metadata={"mock": True, "support_type": support_type}
        )
    
    # <summary>LLMã‚’ä½¿ç”¨ã—ã¦è‡ªç„¶ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ï¼ˆPhase 2ã§å®Ÿè£…ï¼‰ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    # <arg name="user_message">ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚</arg>
    # <returns>LLMç”Ÿæˆå¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚</returns>
    def _generate_llm_response(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str],
        user_message: str
    ) -> TurnPackage:
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆprompt.pyã‹ã‚‰ç”Ÿæˆï¼‰
        prompt = generate_response_prompt(selected_acts, support_type, state, user_message)
        
        try:
            messages = [
                {"role": "system", "content": "ã‚ãªãŸã¯å­¦ç¿’æ”¯æ´ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            response = self.llm_client.generate_response(messages)
            result = json.loads(response)
            
            return TurnPackage(
                natural_reply=result.get("natural_reply", "ã©ã®ã‚ˆã†ãªãŠæ‰‹ä¼ã„ãŒã§ãã¾ã™ã‹ï¼Ÿ"),
                followups=result.get("followups", [])[:3],
                metadata={"support_type": support_type}
            )
            
        except Exception as e:
            logger.error(f"LLMå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_mock_response(state, support_type, selected_acts)
    
    # <summary>ä¼šè©±ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°ã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    def _update_metrics(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str]
    ):
        
        # ã‚¿ãƒ¼ãƒ³æ•°ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
        self.metrics.turns_count += 1
        
        # å‰é€²æ„Ÿã®æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if state.progress_signal.actions_in_last_7_days > 3:
            self.metrics.momentum_delta = 0.5
        elif state.progress_signal.looping_signals:
            self.metrics.momentum_delta = -0.2
        else:
            self.metrics.momentum_delta = 0.1
    
    # <summary>ä¼šè©±å±¥æ­´ã‚’æ›´æ–°ã—ã¾ã™ã€‚</summary>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    # <arg name="response_package">å¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚</arg>
    def _update_history(
        self,
        support_type: str,
        selected_acts: List[str],
        response_package: TurnPackage
    ):
        
        self.support_type_history.append(support_type)
        self.act_history.append(selected_acts)
        
        # æœ€å¤§å±¥æ­´æ•°ã‚’åˆ¶é™
        if len(self.support_type_history) > 20:
            self.support_type_history = self.support_type_history[-20:]
        if len(self.act_history) > 20:
            self.act_history = self.act_history[-20:]
    
    # <summary>ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</summary>
    # <arg name="error_message">ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚</arg>
    # <returns>ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”è¾æ›¸ã€‚</returns>
    def _generate_fallback_response(self, error_message: str) -> Dict[str, Any]:
        
        logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ç”Ÿæˆ: {error_message}")
        
        return {
            "response": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠèã‹ã›ãã ã•ã„ã€‚",
            "followups": [
                "åˆ¥ã®è¨€ã„æ–¹ã§èª¬æ˜ã—ã¦ã¿ã¦ãã ã•ã„",
                "å…·ä½“çš„ãªä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„",
                "ã©ã®éƒ¨åˆ†ãŒç‰¹ã«é‡è¦ã§ã™ã‹ï¼Ÿ"
            ],
            "support_type": SupportType.UNDERSTANDING,
            "selected_acts": [SpeechAct.CLARIFY],
            "state_snapshot": {},
            "decision_metadata": {"error": error_message},
            "metrics": self.metrics.dict()
        }
    
    # <summary>ç¾åœ¨ã®ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¦ç´„ã‚’å–å¾—ã—ã¾ã™ã€‚</summary>
    # <returns>ä¼šè©±è¦ç´„è¾æ›¸ï¼ˆtotal_turns, momentum_delta, support_types_usedç­‰ï¼‰ã€‚</returns>
    def get_conversation_summary(self) -> Dict[str, Any]:
        
        return {
            "total_turns": self.metrics.turns_count,
            "momentum_delta": self.metrics.momentum_delta,
            "support_types_used": list(set(self.support_type_history)),
            "most_common_acts": self._get_most_common_acts(),
            "effectiveness": self._calculate_effectiveness()
        }
    
    # <summary>æœ€ã‚‚é »ç¹ã«ä½¿ç”¨ã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚</summary>
    # <returns>ä¸Šä½3ã¤ã®ç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</returns>
    def _get_most_common_acts(self) -> List[str]:
        
        act_counts = {}
        for acts in self.act_history:
            for act in acts:
                act_counts[act] = act_counts.get(act, 0) + 1
        
        sorted_acts = sorted(act_counts.items(), key=lambda x: x[1], reverse=True)
        return [act for act, _ in sorted_acts[:3]]
    
    # <summary>ä¼šè©±ã®åŠ¹æœã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã™ï¼ˆç°¡æ˜“ç‰ˆï¼‰ã€‚</summary>
    # <returns>åŠ¹æœã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰ã€‚</returns>
    def _calculate_effectiveness(self) -> float:
        
        if self.metrics.turns_count == 0:
            return 0.5
        
        # å‰é€²æ„Ÿã¨ç¶™ç¶šç‡ã‹ã‚‰åŠ¹æœã‚’æ¨å®š
        effectiveness = 0.5 + self.metrics.momentum_delta * 0.3
        if self.metrics.turns_count > 3:
            effectiveness += 0.2  # ç¶™ç¶šãƒœãƒ¼ãƒŠã‚¹
        
        return min(1.0, max(0.0, effectiveness))