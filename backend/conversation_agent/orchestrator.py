"""
å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµ±åˆåˆ¶å¾¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆPhase 1: ãƒ¢ãƒƒã‚¯ç‰ˆï¼‰
ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ã¦å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚’åˆ¶å¾¡
"""
import json
import logging
import sys
import os
import re

from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime
from .schema import (
    StateSnapshot,
    TurnDecision,
    TurnPackage,
    SupportType,
    SpeechAct,
    ConversationMetrics,
    ProjectPlan
)
from .state_extractor import StateExtractor
from .support_typer import SupportTyper
from .policies import PolicyEngine
from .project_planner import ProjectPlanner

# prompt.pyã¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
from prompt.prompt import generate_response_prompt

logger = logging.getLogger(__name__)

class ConversationOrchestrator:
    """å¯¾è©±ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’çµ±åˆåˆ¶å¾¡"""
    
    # <summary>å¯¾è©±ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚</summary>
    # <arg name="llm_client">LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆæ—¢å­˜ã®module.llm_apiã‚’ä½¿ç”¨ï¼‰ã€‚</arg>
    # <arg name="use_mock">ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã™ã‚‹ã‹ï¼ˆPhase 1ã§ã¯Trueï¼‰ã€‚</arg>
    def __init__(self, llm_client=None, use_mock: bool = False):
        self.llm_client = llm_client
        self.use_mock = use_mock
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.state_extractor = StateExtractor(llm_client)
        self.project_planner = ProjectPlanner(llm_client)
        self.support_typer = SupportTyper(llm_client)
        self.policy_engine = PolicyEngine()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡
        self.metrics = ConversationMetrics()
        
        # ä¼šè©±å±¥æ­´ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        self.conversation_history: List[Dict[str, Any]] = []
        self.support_type_history: List[str] = []
        self.act_history: List[List[str]] = []

        # æ—¢å­˜ã®LLMå¿œç­”ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã€é©å¿œå‹ãƒ­ã‚¸ãƒƒã‚¯ã«å·®ã—æ›¿ãˆ
        # æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®å‘¼ã³å‡ºã—ç®‡æ‰€ã‚’æœ€å°å¤‰æ›´ã«ã™ã‚‹ãŸã‚ã€å®Ÿä½“ã‚’å·®ã—æ›¿ãˆã‚‹
        try:
            self._generate_llm_response  # å­˜åœ¨ç¢ºèª
            # å®Ÿè¡Œæ™‚ã«é©å¿œå‹ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã‚¨ã‚¤ãƒªã‚¢ã‚¹
            self._generate_llm_response = self._generate_llm_response_adaptive  # type: ignore
        except Exception:
            pass
    
    # <summary>1ã‚¿ãƒ¼ãƒ³ã®å¯¾è©±å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆï¼‰ã€‚</summary>
    # <arg name="user_message">ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚</arg>
    # <arg name="conversation_history">ä¼šè©±å±¥æ­´ã€‚</arg>
    # <arg name="project_context">ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="user_id">ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="conversation_id">ä¼šè©±IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <returns>å¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆresponse, followups, support_type, selected_acts, state_snapshot, project_plan, decision_metadata, metricsï¼‰ã€‚</returns>
    def process_turn(
        self,
        user_message: str,
        conversation_history: List[Dict[str, str]],
        project_context: Optional[Dict[str, Any]] = None,
        user_id: Optional[int] = None,
        conversation_id: Optional[str] = None
    ) -> Dict[str, Any]:
        
        logger.info("ğŸš€ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†é–‹å§‹")
        logger.info(f"   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message[:100]}...")
        logger.info(f"   - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {bool(project_context)}")
        logger.info(f"   - å±¥æ­´ä»¶æ•°: {len(conversation_history)}")
        
        # æœ€æ–°ã®å±¥æ­´ã‚’å†…éƒ¨ã«ã‚‚ä¿æŒï¼ˆç°¡æ˜“ï¼‰
        try:
            self.conversation_history = list(conversation_history or [])
        except Exception:
            self.conversation_history = []

        try:
            # 1. çŠ¶æ…‹æŠ½å‡º(ç†è§£)
            logger.info("ğŸ“Š Step 1: çŠ¶æ…‹æŠ½å‡ºé–‹å§‹")
            state = self._extract_state(conversation_history, project_context, user_id, conversation_id)
            logger.info(f"âœ… Step 1å®Œäº†: ç›®æ¨™={state.goal or 'æœªè¨­å®š'}, ç›®çš„={state.purpose or 'æœªè¨­å®š'}")
            
            # 2. è¨ˆç”»æ€è€ƒãƒ•ã‚§ãƒ¼ã‚ºï¼ˆæ€è€ƒï¼‰
            logger.info("ğŸ¯ Step 2: è¨ˆç”»æ€è€ƒãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹")
            project_plan = self._generate_project_plan(state, conversation_history)
            if project_plan:
                logger.info(f"âœ… Step 2å®Œäº†: åŒ—æ¥µæ˜Ÿ={project_plan.north_star[:50]}...")
            else:
                logger.info("âš ï¸ Step 2å®Œäº†: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ãªã—")
            
            # 3. æ”¯æ´ã‚¿ã‚¤ãƒ—åˆ¤å®š
            logger.info("ğŸ” Step 3: æ”¯æ´ã‚¿ã‚¤ãƒ—åˆ¤å®šé–‹å§‹")
            support_type, support_reason, confidence = self._determine_support_type(state)
            logger.info(f"âœ… Step 3å®Œäº†: æ”¯æ´ã‚¿ã‚¤ãƒ—={support_type}, ç¢ºä¿¡åº¦={confidence}")
            
            # 4. ç™ºè©±ã‚¢ã‚¯ãƒˆé¸æŠ
            logger.info("ğŸ’¬ Step 4: ç™ºè©±ã‚¢ã‚¯ãƒˆé¸æŠé–‹å§‹")
            selected_acts, act_reason = self._select_acts(state, support_type)
            logger.info(f"âœ… Step 4å®Œäº†: ã‚¢ã‚¯ãƒˆ={selected_acts}")
            
            # 5. å¿œç­”ç”Ÿæˆ
            logger.info("ğŸ“ Step 5: å¿œç­”ç”Ÿæˆé–‹å§‹")
            response_package = self._generate_llm_response(
                state, support_type, selected_acts, user_message
            )
            logger.info(f"âœ… Step 5å®Œäº†: å¿œç­”æ–‡å­—æ•°={len(response_package.natural_reply)}")
            
            # 6. ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self._update_metrics(state, support_type, selected_acts)
            
            # 7. å±¥æ­´æ›´æ–°
            self._update_history(support_type, selected_acts, response_package)
            
            # çµæœã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
            result = {
                "response": response_package.natural_reply,
                "followups": response_package.followups,
                "support_type": support_type,
                "selected_acts": selected_acts,
                "state_snapshot": state.dict(exclude={'user_id', 'conversation_id', 'turn_index'}),
                "project_plan": project_plan.dict() if project_plan else None,  # NEW!
                "decision_metadata": {
                    "support_reason": support_reason,
                    "support_confidence": confidence,
                    "act_reason": act_reason,
                    "timestamp": datetime.now().isoformat()
                },
                "metrics": self.metrics.dict()
            }
            
            logger.info("ğŸ‰ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†å®Œäº†")
            return result
            
        except Exception as e:
            import traceback
            logger.error(f"âŒ å¯¾è©±å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(f"âŒ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
            return self._generate_fallback_response(str(e))
    
    # <summary>ä¼šè©±å±¥æ­´ã‹ã‚‰ç¾åœ¨ã®çŠ¶æ…‹ã‚’æŠ½å‡ºã—ã¾ã™ã€‚</summary>
    # <arg name="conversation_history">ä¼šè©±å±¥æ­´ã€‚</arg>
    # <arg name="project_context">ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="user_id">ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <arg name="conversation_id">ä¼šè©±IDï¼ˆä»»æ„ï¼‰ã€‚</arg>
    # <returns>ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</returns>
    def _extract_state(
        self,
        conversation_history: List[Dict[str, str]],
        project_context: Optional[Dict[str, Any]],
        user_id: Optional[int],
        conversation_id: Optional[str]
    ) -> StateSnapshot:
        """çŠ¶æ…‹æŠ½å‡ºãƒ•ã‚§ãƒ¼ã‚ºï¼ˆä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ï¼‰"""
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¯ä½¿ç”¨ã—ãªã„ï¼ˆä¼šè©±å±¥æ­´ã‹ã‚‰æ¨æ¸¬ï¼‰
        logger.info("ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹æŠ½å‡ºã‚’é–‹å§‹")
        
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯å‡¦ç†ã‚’ä½¿ç”¨
        use_llm = not self.use_mock and self.llm_client is not None
        
        state = self.state_extractor.extract_from_history(
            conversation_history,
            None,  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¯æ¸¡ã•ãªã„
            use_llm=use_llm,
            mock_mode=True  # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«é™å®šï¼ˆã‚´ãƒ¼ãƒ«ã€ç›®çš„ã€ProjectContextã€ä¼šè©±å±¥æ­´ï¼‰
        )
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¿½åŠ 
        state.user_id = user_id
        state.conversation_id = conversation_id
        state.turn_index = len(conversation_history)
        
        # ä¼šè©±å±¥æ­´ã‹ã‚‰ç›®æ¨™ã‚’æ¨æ¸¬ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        if not state.goal and conversation_history:
            # æœ€åˆã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ç›®æ¨™ã‚’æ¨æ¸¬
            for msg in conversation_history:
                if msg.get('sender') == 'user':
                    state.goal = msg['message'][:100]  # æœ€åˆã®100æ–‡å­—ã‚’æš«å®šçš„ãªç›®æ¨™ã¨ã™ã‚‹
                    break
        
        logger.info(f"çŠ¶æ…‹æŠ½å‡ºå®Œäº†: goal={state.goal}, blockers={len(state.blockers)}")
        
        return state
    
    # <summary>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="conversation_history">ä¼šè©±å±¥æ­´ã€‚</arg>
    # <returns>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ï¼ˆä»»æ„ï¼‰ã€‚</returns>
    def _generate_project_plan(
        self,
        state: StateSnapshot,
        conversation_history: List[Dict[str, str]]
    ) -> Optional[ProjectPlan]:
        
        # ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§ã¯è¨ˆç”»æ€è€ƒã‚’ã‚¹ã‚­ãƒƒãƒ—
        logger.info("ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚ã€è¨ˆç”»æ€è€ƒãƒ•ã‚§ãƒ¼ã‚ºã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return None
        
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹å‡¦ç†ã‚’ä½¿ç”¨
        use_llm = not self.use_mock and self.llm_client is not None
        
        try:
            project_plan = self.project_planner.generate_project_plan(
                state,
                conversation_history,
                use_llm=use_llm
            )
            
            logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ç”Ÿæˆå®Œäº†: åŒ—æ¥µæ˜Ÿ={project_plan.north_star[:50]}...")
            logger.info(f"æ¬¡ã®è¡Œå‹•æ•°: {len(project_plan.next_actions)}, ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³æ•°: {len(project_plan.milestones)}")
            
            return project_plan
            
        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    # <summary>çŠ¶æ…‹ã‹ã‚‰æ”¯æ´ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <returns>(support_type, reason, confidence)ã€‚æ”¯æ´ã‚¿ã‚¤ãƒ—ã€ç†ç”±ã€ç¢ºä¿¡åº¦ã€‚</returns>
    def _determine_support_type(self, state: StateSnapshot) -> Tuple[str, str, float]:
        
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹å‡¦ç†ã‚’ä½¿ç”¨
        use_llm = not self.use_mock and self.llm_client is not None
        
        support_type, reason, confidence = self.support_typer.determine_support_type(
            state,
            use_llm=use_llm
        )
        
        # æ–‡è„ˆã«åŸºã¥ãèª¿æ•´
        if self.support_type_history:
            effectiveness_scores = {}  # Phase 2ã§å®Ÿè£…
            support_type = self.support_typer.adjust_for_context(
                support_type,
                self.support_type_history[-5:],
                effectiveness_scores
            )
        
        logger.info(f"æ”¯æ´ã‚¿ã‚¤ãƒ—åˆ¤å®š: {support_type} (ç¢ºä¿¡åº¦: {confidence:.2f})")
        
        return support_type, reason, confidence
    
    # <summary>æ”¯æ´ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ç™ºè©±ã‚¢ã‚¯ãƒˆã‚’é¸æŠã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <returns>(selected_acts, reason)ã€‚é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã¨ç†ç”±ã€‚</returns>
    def _select_acts(self, state: StateSnapshot, support_type: str) -> Tuple[List[str], str]:
        
        selected_acts, reason = self.policy_engine.select_acts(
            state,
            support_type,
            max_acts=2
        )
        
        # Socraticå„ªå…ˆé †ä½ã§ä¸¦ã³æ›¿ãˆ
        selected_acts = self.policy_engine.get_socratic_priority(selected_acts)
        
        logger.info(f"ç™ºè©±ã‚¢ã‚¯ãƒˆé¸æŠ: {selected_acts}")
        
        return selected_acts, reason
    
    # <summary>ç™ºè©±ã‚¢ã‚¯ãƒˆã«åŸºã¥ã„ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ï¼ˆPhase 1: ãƒ¢ãƒƒã‚¯ç‰ˆï¼‰ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    # <arg name="user_message">ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚</arg>
    # <returns>å¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚</returns>
    def _generate_response(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str],
        user_message: str
    ) -> TurnPackage:
        
        if self.use_mock or not self.llm_client:
            return self._generate_llm_response(state, support_type, selected_acts)
        
        # Phase 2ã§å®Ÿè£…: LLMã‚’ä½¿ç”¨ã—ãŸè‡ªç„¶æ–‡ç”Ÿæˆ
        return self._generate_llm_response(state, support_type, selected_acts, user_message)
    
    # <summary>ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    # <returns>ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚</returns>
    def _generate_mock_response(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str]
    ) -> TurnPackage:
        
        # ã‚¢ã‚¯ãƒˆã«åŸºã¥ããƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¿œç­”
        responses = {
            SpeechAct.CLARIFY: "ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã©ã®ã‚ˆã†ãªç‚¹ã§å›°ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            SpeechAct.INFORM: "ã“ã®åˆ†é‡ã§ã¯ã€ã¾ãšåŸºæœ¬çš„ãªæ¦‚å¿µã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚",
            SpeechAct.PROBE: "ãªãœãã‚ŒãŒé‡è¦ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿã©ã®ã‚ˆã†ãªæˆæœã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            SpeechAct.ACT: "ã¾ãšã¯30åˆ†ã§ã€å…·ä½“çš„ãªä¾‹ã‚’3ã¤æ›¸ãå‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚",
            SpeechAct.REFRAME: "åˆ¥ã®è§’åº¦ã‹ã‚‰è¦‹ã‚‹ã¨ã€ã“ã‚Œã¯å­¦ç¿’ã®æ©Ÿä¼šã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚",
            SpeechAct.OUTLINE: "ã“ã‚Œã‚’3ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†ã‘ã¦ã¿ã¾ã—ã‚‡ã†ï¼š1) èª¿æŸ»ã€2) å®Ÿé¨“ã€3) æŒ¯ã‚Šè¿”ã‚Šã€‚",
            SpeechAct.DECIDE: "ã©ã®é¸æŠè‚¢ãŒæœ€ã‚‚ç›®æ¨™ã«è¿‘ã¥ã‘ãã†ã§ã™ã‹ï¼ŸåŸºæº–ã‚’æ˜ç¢ºã«ã—ã¾ã—ã‚‡ã†ã€‚",
            SpeechAct.REFLECT: "ã“ã“ã¾ã§ã®è©±ã‚’ã¾ã¨ã‚ã‚‹ã¨ã€ä¸»ãªèª²é¡Œã¯æ˜ç¢ºã«ãªã£ã¦ãã¾ã—ãŸã­ã€‚"
        }
        
        # é¸æŠã•ã‚ŒãŸã‚¢ã‚¯ãƒˆã«åŸºã¥ã„ã¦å¿œç­”ã‚’æ§‹ç¯‰
        response_parts = []
        for act in selected_acts[:2]:
            if act in responses:
                response_parts.append(responses[act])
        
        natural_reply = " ".join(response_parts) if response_parts else "ã©ã®ã‚ˆã†ãªã“ã¨ã§ãŠå›°ã‚Šã§ã™ã‹ï¼Ÿ"
        
        # ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—å€™è£œ
        followups = [
            "å…·ä½“ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "ä»–ã®æ–¹æ³•ã‚‚æ¤œè¨ã—ã¾ã—ã‚‡ã†",
            "ã¾ãšã¯å°ã•ãå§‹ã‚ã¦ã¿ã¾ã™"
        ]
        
        return TurnPackage(
            natural_reply=natural_reply,
            followups=followups[:3],
            metadata={"mock": True, "support_type": support_type}
        )
    
    # æ–°è¦: é©å¿œå‹LLMå¿œç­”ç”Ÿæˆï¼ˆæ–‡é‡ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è‡ªå‹•èª¿æ•´ï¼‰[2025.9.15 mori]
    def _generate_llm_response_adaptive(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str],
        user_message: str
    ) -> TurnPackage:
        """
        å…¥åŠ›é•·ãƒ»èªå½™ãƒ»å±¥æ­´ãƒ»é€²æ—ã‹ã‚‰å‹•æ©Ÿã¥ã‘/ç†è§£åº¦ã‚’æ¨å®šã—ã€
        é©åˆ‡ãªæ–‡é‡ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã§LLMã«æŒ‡ç¤ºã—ã¦å¿œç­”ã‚’å¾—ã‚‹ã€‚
        """

        motivation_score, understanding_score = self._assess_motivation_and_understanding(
            user_message, state, self.conversation_history
        )

        profile = self._decide_response_profile(
            motivation_score, understanding_score, state, self.conversation_history, support_type
        )

        guidelines = self._build_guidelines(profile, motivation_score, understanding_score, state)

        blockers_str = ", ".join(state.blockers) if getattr(state, 'blockers', None) else "ãªã—"
        uncertainties_str = ", ".join(state.uncertainties) if getattr(state, 'uncertainties', None) else "ãªã—"
        selected_acts_str = ", ".join(selected_acts)

        prompt = (
            "ã‚ãªãŸã¯æ¢ç©¶å­¦ç¿’ã®ãƒ¡ãƒ³ã‚¿ãƒ¼AIã§ã™ã€‚å­¦ç¿’ç§‘å­¦ãƒ»å‹•æ©Ÿã¥ã‘ç†è«–ã«åŸºã¥ãã€\n"
            "éå‰°ãªèª¬æ˜ã¯é¿ã‘ã€çŸ­ã„å¯¾è©±ã®ãƒ†ãƒ³ãƒã§å‰é€²ã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚\n\n"
            f"æ”¯æ´ã‚¿ã‚¤ãƒ—: {support_type}\n"
            f"ç™ºè©±ã‚¢ã‚¯ãƒˆ: {selected_acts_str}\n"
            "å­¦ç¿’çŠ¶æ…‹:\n"
            f"- ç›®æ¨™: {getattr(state, 'goal', '')}\n"
            f"- ãƒ–ãƒ­ãƒƒã‚«ãƒ¼: {blockers_str}\n"
            f"- ä¸ç¢ºå®Ÿæ€§: {uncertainties_str}\n\n"
            f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message}\n\n"
            f"å¿œç­”ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³:\n{guidelines}\n\n"
            "å‡ºåŠ›ã¯å¿…ãšæ¬¡ã®JSONã§è¿”ã—ã¦ãã ã•ã„ï¼ˆä½™è¨ˆãªãƒ†ã‚­ã‚¹ãƒˆã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ç¦æ­¢ï¼‰ã€‚\n"
            "{\n"
            "  \"natural_reply\": \"æŒ‡ç¤ºã«æ²¿ã£ãŸæ—¥æœ¬èªã®å¿œç­”æ–‡\",\n"
            "  \"followups\": [\"çŸ­ã„ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—1\", \"çŸ­ã„ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—2\", \"çŸ­ã„ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—3\"]\n"
            "}"
        )

        try:
            messages = [
                {"role": "system", "content": "ã‚ãªãŸã¯å­¦ç¿’æ”¯æ´ã®å°‚é–€å®¶ã§ã™ã€‚æ—¥æœ¬èªã§ä¸å¯§ã«å¿œç­”ã—ã€å¿…ãšæœ‰åŠ¹ãªJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚"},
                {"role": "user", "content": prompt}
            ]

            response = self.llm_client.generate_response_with_history(messages)

            # JSONæŠ½å‡ºã®å …ç‰¢åŒ–
            try:
                json_str = response
                match = re.search(r"\{[\s\S]*\}\s*$", response)
                if match:
                    json_str = match.group(0)
                result = json.loads(json_str)
            except Exception:
                result = json.loads(response)

            return TurnPackage(
                natural_reply=result.get("natural_reply", "ã©ã®ã‚ˆã†ãªãŠæ‰‹ä¼ã„ãŒã§ãã¾ã™ã‹ï¼Ÿ"),
                followups=result.get("followups", [])[:3],
                metadata={
                    "support_type": support_type,
                    "profile": profile,
                    "motivation_score": motivation_score,
                    "understanding_score": understanding_score,
                }
            )

        except Exception as e:
            logger.error(f"LLMå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_mock_response(state, support_type, selected_acts)

    def _assess_motivation_and_understanding(
        self,
        user_message: str,
        state: StateSnapshot,
        history: List[Dict[str, Any]],
    ) -> Tuple[float, float]:
        """0.0ã€œ1.0ã§å‹•æ©Ÿã¥ã‘/ç†è§£åº¦ã‚’æ¨å®šï¼ˆç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹ï¼‰ã€‚"""
        text = (user_message or "").strip()
        length = len(text)
        neg_words = ["ã‚ã‹ã‚‰ãªã„", "ç„¡ç†", "ã§ããªã„", "é›£ã—ã„", "ã‚€ãšã‹ã—ã„", "ç–²ã‚ŒãŸ", "ã‚„ã‚ãŸã„", "ã¤ã‚‰ã„"]
        neg_hits = sum(w in text for w in neg_words)

        # å‹•æ©Ÿã¥ã‘
        base = 0.6 if length >= 50 else 0.4 if length >= 15 else 0.25
        base -= 0.1 * min(2, neg_hits)
        try:
            interest = getattr(state.affect, 'interest', 0) or 0
            anxiety = getattr(state.affect, 'anxiety', 0) or 0
        except Exception:
            interest, anxiety = 0, 0
        base += (interest - 2) * 0.07
        base -= (anxiety - 2) * 0.07
        try:
            actions = getattr(state.progress_signal, 'actions_in_last_7_days', 0) or 0
        except Exception:
            actions = 0
        base += min(0.2, actions * 0.03)
        motivation = max(0.0, min(1.0, base))

        # ç†è§£åº¦
        vague_words = ["ãªã‚“ã¨ãªã", "ã‚ˆã", "å¤šåˆ†", "ãŸã¶ã‚“", "ã¨ã‚Šã‚ãˆãš", "ã©ã†ã™ã‚Œã°"]
        vague_hits = sum(w in text for w in vague_words)
        understanding_base = 0.5 + (0.2 if length >= 80 else 0.1 if length >= 40 else -0.05)
        understanding_base -= 0.08 * min(2, vague_hits)
        understanding_base -= 0.08 * min(2, neg_hits)
        understanding = max(0.0, min(1.0, understanding_base))

        return motivation, understanding

    def _decide_response_profile(
        self,
        motivation: float,
        understanding: float,
        state: StateSnapshot,
        history: List[Dict[str, Any]],
        support_type: str,
    ) -> Dict[str, Any]:
        """å¿œç­”ã®æ–‡é‡ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—æ–¹é‡ã‚’æ±ºå®šã€‚"""
        turns = len(history)
        try:
            actions = getattr(state.progress_signal, 'actions_in_last_7_days', 0) or 0
        except Exception:
            actions = 0

        if motivation < 0.35 or understanding < 0.35:
            target = 80
        elif motivation < 0.55 or understanding < 0.55:
            target = 160
        elif actions > 3 or turns > 6:
            target = 300
        else:
            target = 200

        style = {
            "normalize": motivation < 0.45,
            "socratic": True,
            "micro_task": motivation >= 0.4,
            "offer_choices": understanding < 0.5,
            "reflect": True,
        }

        return {
            "target_chars": target,
            "style": style,
        }

    def _build_guidelines(
        self,
        profile: Dict[str, Any],
        motivation: float,
        understanding: float,
        state: StateSnapshot,
    ) -> str:
        t = profile["target_chars"]
        style = profile["style"]
        if t <= 90:
            length_text = "60ã€œ90æ–‡å­—"
        elif t <= 160:
            length_text = "120ã€œ180æ–‡å­—"
        elif t <= 220:
            length_text = "180ã€œ260æ–‡å­—"
        elif t <= 320:
            length_text = "240ã€œ360æ–‡å­—"
        else:
            length_text = "300ã€œ420æ–‡å­—"

        parts = [
            f"æ–‡é‡ã¯{length_text}ã€‚",
            "å°‚é–€ç”¨èªã¯é¿ã‘ã€çŸ­ã„æ–‡ã§ã€‚",
            "åŸå‰‡ã¨ã—ã¦è³ªå•ã¯1ã€œ2å€‹ã¾ã§ã§è² è·ã‚’ä¸Šã’ãªã„ã€‚",
            "æ®µè½ã¯æœ€å¤§2ã¤ã€‚ç®‡æ¡æ›¸ãã¯3ç‚¹ä»¥å†…ã€‚",
        ]
        if style.get("normalize"):
            parts.append("æœ€åˆã«å®‰å¿ƒã¥ã‘ã®ä¸€è¨€ï¼ˆè‚¯å®šãƒ»å…±æ„Ÿï¼‰ã‚’çŸ­ãå…¥ã‚Œã‚‹ã€‚")
        if style.get("socratic"):
            parts.append("å•ã„ã‹ã‘ä¸­å¿ƒã§æ€è€ƒã‚’å‰ã«é€²ã‚ã‚‹ã€‚")
        if style.get("micro_task"):
            parts.append("æ¬¡ã®ä¸€æ­©ã¯5ã€œ10åˆ†ã§ã§ãã‚‹æ¥µå°ã‚¿ã‚¹ã‚¯ã¨ã—ã¦1ã¤ã ã‘ææ¡ˆã€‚")
        if style.get("offer_choices"):
            parts.append("é¸æŠè‚¢ã‚’2ã€œ3å€‹ã«é™å®šã—ã€ã©ã‚Œã‹ä¸€ã¤ã‚’é¸ã¹ã°é€²ã‚ã‚‹å½¢ã«ã™ã‚‹ã€‚")
        if style.get("reflect"):
            parts.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã®è¦ç‚¹ã‚’1æ–‡ã§é¡å†™ã—ã«ã—ã¦ã‹ã‚‰ç¶šã‘ã‚‹ã€‚")

        parts.append(
            "followupsé…åˆ—ã«ã¯ã€ã•ã‚‰ã«è»½ã„ç¢ºèªè³ªå•/é¸æŠè‚¢/æ¬¡ã®ä¸€æ­©ã®ã„ãšã‚Œã‹ã‚’3ä»¶ã€å„15æ–‡å­—ä»¥å†…ã§ã€‚"
        )

        return "\n".join(parts)
    
    # <summary>LLMã‚’ä½¿ç”¨ã—ã¦è‡ªç„¶ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ï¼ˆPhase 2ã§å®Ÿè£…ï¼‰ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    # <arg name="user_message">ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚</arg>
    # <returns>LLMç”Ÿæˆå¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚</returns>
    def _generate_llm_response(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str],
        user_message: str
    ) -> TurnPackage:
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆprompt.pyã‹ã‚‰ç”Ÿæˆï¼‰
        prompt = generate_response_prompt(selected_acts, support_type, state, user_message)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›æ–‡å­—æ•°ã«åŸºã¥ã„ã¦å¿œç­”ã®é•·ã•ã‚’æ±ºå®š
        input_length = len(user_message)
        if input_length < 20:
            response_length_instruction = "ç°¡æ½”ã«ã€ãŠã‚ˆã80æ–‡å­—ç¨‹åº¦ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
        elif input_length < 100:
            response_length_instruction = "ãŠã‚ˆã200æ–‡å­—ç¨‹åº¦ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
        else:
            response_length_instruction = "å°‘ã—è©³ã—ã‚ã«ã€ãŠã‚ˆã400æ–‡å­—ç¨‹åº¦ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚"

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = f"""ã‚ãªãŸã¯æ¢ç©¶å­¦ç¿’ã®ãƒ¡ãƒ³ã‚¿ãƒ¼AIã§ã™ã€‚
        
é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆ: {selected_acts}
æ”¯æ´ã‚¿ã‚¤ãƒ—: {support_type}
å­¦ç¿’è€…ã®çŠ¶æ…‹:
- ç›®æ¨™: {state.goal}
- ãƒ–ãƒ­ãƒƒã‚«ãƒ¼: {', '.join(state.blockers) if state.blockers else 'ãªã—'}
- ä¸ç¢ºå®Ÿæ€§: {', '.join(state.uncertainties) if state.uncertainties else 'ãªã—'}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message}

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆã‚’è‡ªç„¶ã«çµ„ã¿åˆã‚ã›ãŸå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
Socraticï¼ˆå•ã„ã‹ã‘ä¸­å¿ƒï¼‰ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å„ªå…ˆã—ã€å¿…è¦æœ€å°é™ã®æƒ…å ±æä¾›ã«ç•™ã‚ã¦ãã ã•ã„ã€‚
{response_length_instruction}

å¿œç­”å½¢å¼ï¼ˆJSONï¼‰:
{{
    "natural_reply": "è‡ªç„¶ãªå¿œç­”æ–‡",
    "followups": ["ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—1", "ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—2", "ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—3"]
}}"""
        
        try:
            messages = [
                {"role": "system", "content": "ã‚ãªãŸã¯å­¦ç¿’æ”¯æ´ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            response = self.llm_client.generate_response(messages)
            result = json.loads(response)
            
            return TurnPackage(
                natural_reply=result.get("natural_reply", "ã©ã®ã‚ˆã†ãªãŠæ‰‹ä¼ã„ãŒã§ãã¾ã™ã‹ï¼Ÿ"),
                followups=result.get("followups", [])[:3],
                metadata={"support_type": support_type}
            )
            
        except Exception as e:
            logger.error(f"LLMå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_mock_response(state, support_type, selected_acts)
    
    # <summary>ä¼šè©±ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°ã—ã¾ã™ã€‚</summary>
    # <arg name="state">ç¾åœ¨ã®çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€‚</arg>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    def _update_metrics(
        self,
        state: StateSnapshot,
        support_type: str,
        selected_acts: List[str]
    ):
        
        # ã‚¿ãƒ¼ãƒ³æ•°ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
        self.metrics.turns_count += 1
        
        # å‰é€²æ„Ÿã®æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if state.progress_signal.actions_in_last_7_days > 3:
            self.metrics.momentum_delta = 0.5
        elif state.progress_signal.looping_signals:
            self.metrics.momentum_delta = -0.2
        else:
            self.metrics.momentum_delta = 0.1
    
    # <summary>ä¼šè©±å±¥æ­´ã‚’æ›´æ–°ã—ã¾ã™ã€‚</summary>
    # <arg name="support_type">é¸æŠã•ã‚ŒãŸæ”¯æ´ã‚¿ã‚¤ãƒ—ã€‚</arg>
    # <arg name="selected_acts">é¸æŠã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</arg>
    # <arg name="response_package">å¿œç­”ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚</arg>
    def _update_history(
        self,
        support_type: str,
        selected_acts: List[str],
        response_package: TurnPackage
    ):
        
        self.support_type_history.append(support_type)
        self.act_history.append(selected_acts)
        
        # æœ€å¤§å±¥æ­´æ•°ã‚’åˆ¶é™
        if len(self.support_type_history) > 20:
            self.support_type_history = self.support_type_history[-20:]
        if len(self.act_history) > 20:
            self.act_history = self.act_history[-20:]
    
    # <summary>ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</summary>
    # <arg name="error_message">ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚</arg>
    # <returns>ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”è¾æ›¸ã€‚</returns>
    def _generate_fallback_response(self, error_message: str) -> Dict[str, Any]:
        
        logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ç”Ÿæˆ: {error_message}")
        
        return {
            "response": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠèã‹ã›ãã ã•ã„ã€‚",
            "followups": [
                "åˆ¥ã®è¨€ã„æ–¹ã§èª¬æ˜ã—ã¦ã¿ã¦ãã ã•ã„",
                "å…·ä½“çš„ãªä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„",
                "ã©ã®éƒ¨åˆ†ãŒç‰¹ã«é‡è¦ã§ã™ã‹ï¼Ÿ"
            ],
            "support_type": SupportType.UNDERSTANDING,
            "selected_acts": [SpeechAct.CLARIFY],
            "state_snapshot": {},
            "decision_metadata": {"error": error_message},
            "metrics": self.metrics.dict()
        }
    
    # <summary>ç¾åœ¨ã®ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¦ç´„ã‚’å–å¾—ã—ã¾ã™ã€‚</summary>
    # <returns>ä¼šè©±è¦ç´„è¾æ›¸ï¼ˆtotal_turns, momentum_delta, support_types_usedç­‰ï¼‰ã€‚</returns>
    def get_conversation_summary(self) -> Dict[str, Any]:
        
        return {
            "total_turns": self.metrics.turns_count,
            "momentum_delta": self.metrics.momentum_delta,
            "support_types_used": list(set(self.support_type_history)),
            "most_common_acts": self._get_most_common_acts(),
            "effectiveness": self._calculate_effectiveness()
        }
    
    # <summary>æœ€ã‚‚é »ç¹ã«ä½¿ç”¨ã•ã‚ŒãŸç™ºè©±ã‚¢ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚</summary>
    # <returns>ä¸Šä½3ã¤ã®ç™ºè©±ã‚¢ã‚¯ãƒˆãƒªã‚¹ãƒˆã€‚</returns>
    def _get_most_common_acts(self) -> List[str]:
        
        act_counts = {}
        for acts in self.act_history:
            for act in acts:
                act_counts[act] = act_counts.get(act, 0) + 1
        
        sorted_acts = sorted(act_counts.items(), key=lambda x: x[1], reverse=True)
        return [act for act, _ in sorted_acts[:3]]
    
    # <summary>ä¼šè©±ã®åŠ¹æœã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã™ï¼ˆç°¡æ˜“ç‰ˆï¼‰ã€‚</summary>
    # <returns>åŠ¹æœã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰ã€‚</returns>
    def _calculate_effectiveness(self) -> float:
        
        if self.metrics.turns_count == 0:
            return 0.5
        
        # å‰é€²æ„Ÿã¨ç¶™ç¶šç‡ã‹ã‚‰åŠ¹æœã‚’æ¨å®š
        effectiveness = 0.5 + self.metrics.momentum_delta * 0.3
        if self.metrics.turns_count > 3:
            effectiveness += 0.2  # ç¶™ç¶šãƒœãƒ¼ãƒŠã‚¹
        
        return min(1.0, max(0.0, effectiveness))
