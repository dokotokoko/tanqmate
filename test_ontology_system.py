"""
ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèªã¨ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import sys
import os
from datetime import datetime
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from backend.conversation_agent.ontology_graph import (
    InquiryOntologyGraph, Node, Edge, NodeType, RelationType
)
from backend.conversation_agent.graph_inference_engine import GraphInferenceEngine
from backend.conversation_agent.ontology_adapter import OntologyAdapter
from backend.ontology.ontology_orchestrator import OntologyOrchestrator
from backend.conversation_agent.schema import StateSnapshot


def test_basic_graph():
    """åŸºæœ¬çš„ãªã‚°ãƒ©ãƒ•æ“ä½œã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª Test 1: åŸºæœ¬çš„ãªã‚°ãƒ©ãƒ•æ“ä½œ")
    print("-" * 50)
    
    # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    graph = InquiryOntologyGraph("ontology.yaml", "constraints.yaml")
    
    # ãƒãƒ¼ãƒ‰ã‚’ä½œæˆ
    question_node = Node(
        id="q_001",
        type=NodeType.QUESTION,
        text="ãªãœæ—¥æœ¬ã®é£Ÿæ–‡åŒ–ã¯åœ°åŸŸã«ã‚ˆã£ã¦ç•°ãªã‚‹ã®ã‹ï¼Ÿ",
        student_id="student_001",
        timestamp=datetime.now(),
        clarity=0.7,
        depth=0.4
    )
    
    hypothesis_node = Node(
        id="h_001",
        type=NodeType.HYPOTHESIS,
        text="åœ°ç†çš„æ¡ä»¶ã¨æ­´å²çš„èƒŒæ™¯ãŒå½±éŸ¿ã—ã¦ã„ã‚‹",
        student_id="student_001",
        timestamp=datetime.now(),
        clarity=0.6,
        depth=0.5
    )
    
    # ã‚°ãƒ©ãƒ•ã«è¿½åŠ 
    graph.add_node(question_node)
    graph.add_node(hypothesis_node)
    
    # ã‚¨ãƒƒã‚¸ã‚’ä½œæˆ
    edge = Edge(
        src=question_node.id,
        rel=RelationType.LEADS_TO,
        dst=hypothesis_node.id,
        confidence=0.8
    )
    graph.add_edge(edge)
    
    print(f"âœ… ãƒãƒ¼ãƒ‰æ•°: {len(graph.nodes)}")
    print(f"âœ… ã‚¨ãƒƒã‚¸æ•°: {len(graph.edges)}")
    print(f"âœ… ç¾åœ¨ä½ç½®: {graph.get_current_position('student_001').type.value}")
    
    return graph


def test_inference_engine(graph):
    """æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª Test 2: æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³")
    print("-" * 50)
    
    engine = GraphInferenceEngine(graph)
    
    # ç¾åœ¨ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰æ¨è«–
    current_node = graph.get_current_position("student_001")
    inference_result = engine.infer_next_step(current_node)
    
    print(f"âœ… æ”¯æ´ã‚¿ã‚¤ãƒ—: {inference_result['support_type']}")
    print(f"âœ… ç™ºè©±ã‚¢ã‚¯ãƒˆ: {inference_result['acts']}")
    print(f"âœ… ç†ç”±: {inference_result['reason']}")
    print(f"âœ… æ¬¡ã®ãƒãƒ¼ãƒ‰: {inference_result['next_node_type'].value}")
    print(f"âœ… ç¢ºä¿¡åº¦: {inference_result['confidence']:.2f}")
    print(f"âœ… é©ç”¨ãƒ«ãƒ¼ãƒ«: {inference_result.get('applied_rule', 'default')}")
    
    # äºˆæ¸¬
    predictions = engine.predict_next_nodes(current_node, depth=3)
    print("\nğŸ“Š æ¬¡ã®3ã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬:")
    for pred in predictions:
        print(f"   Step {pred['step']}: {pred['node_type'].value} "
              f"({pred['support_type']}, ç¢ºä¿¡åº¦: {pred['confidence']:.2f})")
    
    return engine


def test_adapter():
    """ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª Test 3: ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼")
    print("-" * 50)
    
    adapter = OntologyAdapter("ontology.yaml", "constraints.yaml")
    
    # StateSnapshotã‚’ä½œæˆ
    state = StateSnapshot(
        goal="åœ°åŸŸæ–‡åŒ–ã®å¤šæ§˜æ€§ã‚’ç†è§£ã™ã‚‹",
        purpose="æ¢ç©¶å­¦ç¿’ã®ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ",
        project_context={
            "theme": "æ—¥æœ¬ã®é£Ÿæ–‡åŒ–",
            "question": "ãªãœåœ°åŸŸå·®ãŒã‚ã‚‹ã®ã‹",
            "hypothesis": "åœ°ç†ã¨æ­´å²ãŒå½±éŸ¿"
        },
        uncertainties=["å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿åé›†æ–¹æ³•", "æ¯”è¼ƒã®åŸºæº–"],
        blockers=["è³‡æ–™ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹"]
    )
    
    # ã‚°ãƒ©ãƒ•ãƒãƒ¼ãƒ‰ã«å¤‰æ›
    node = adapter.state_to_graph_node(state, "student_001")
    print(f"âœ… ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: {node.type.value}")
    print(f"âœ… æ˜ç¢ºæ€§: {node.clarity:.2f}")
    print(f"âœ… æ·±ã•: {node.depth:.2f}")
    
    # æ”¯æ´ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
    adapter.graph.add_node(node)
    support_type, reason, confidence = adapter.decide_support_type_from_graph(node)
    print(f"âœ… æ¨å¥¨æ”¯æ´: {support_type} (ç†ç”±: {reason})")
    
    # ç™ºè©±ã‚¢ã‚¯ãƒˆã‚’é¸æŠ
    acts, act_reason = adapter.select_acts_from_graph(node, support_type)
    print(f"âœ… ç™ºè©±ã‚¢ã‚¯ãƒˆ: {acts}")
    
    return adapter


def test_orchestrator():
    """çµ±åˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª Test 4: æ‹¡å¼µç‰ˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼")
    print("-" * 50)
    
    # ã‚°ãƒ©ãƒ•ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–
    orchestrator = OntologyOrchestrator(
        use_mock=True,
        use_graph=True,
        ontology_path="ontology.yaml",
        constraints_path="constraints.yaml"
    )
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
    result = orchestrator.process_turn(
        user_message="æ—¥æœ¬ã®é£Ÿæ–‡åŒ–ã«ã¤ã„ã¦èª¿ã¹ãŸã„ã®ã§ã™ãŒã€ã©ã“ã‹ã‚‰å§‹ã‚ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ",
        conversation_history=[],
        user_id=1
    )
    
    print(f"âœ… å¿œç­”: {result['response'][:100]}...")
    print(f"âœ… æ”¯æ´ã‚¿ã‚¤ãƒ—: {result['support_type']}")
    print(f"âœ… ç™ºè©±ã‚¢ã‚¯ãƒˆ: {result['selected_acts']}")
    print(f"âœ… ãƒ¢ãƒ¼ãƒ‰: {result['decision_metadata']['mode']}")
    
    if 'graph_context' in result:
        ctx = result['graph_context']
        print(f"âœ… ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚º: {ctx['graph_size']} ãƒãƒ¼ãƒ‰")
        print(f"âœ… é€²æ—: {ctx['progress']}")
    
    return orchestrator


def test_cycle_detection():
    """å¾ªç’°æ¤œå‡ºã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª Test 5: å¾ªç’°ãƒ‘ã‚¹ã®æ¤œå‡º")
    print("-" * 50)
    
    graph = InquiryOntologyGraph("ontology.yaml", "constraints.yaml")
    
    # å¾ªç’°ã™ã‚‹ãƒãƒ¼ãƒ‰ã‚’ä½œæˆ
    nodes = [
        Node(id="q1", type=NodeType.QUESTION, text="å•ã„", student_id="s1", timestamp=datetime.now()),
        Node(id="h1", type=NodeType.HYPOTHESIS, text="ä»®èª¬", student_id="s1", timestamp=datetime.now()),
        Node(id="m1", type=NodeType.METHOD, text="æ–¹æ³•", student_id="s1", timestamp=datetime.now()),
        Node(id="d1", type=NodeType.DATA, text="ãƒ‡ãƒ¼ã‚¿", student_id="s1", timestamp=datetime.now()),
        Node(id="i1", type=NodeType.INSIGHT, text="æ´å¯Ÿ", student_id="s1", timestamp=datetime.now()),
        Node(id="h2", type=NodeType.HYPOTHESIS, text="ä¿®æ­£ä»®èª¬", student_id="s1", timestamp=datetime.now()),
    ]
    
    for node in nodes:
        graph.add_node(node)
    
    # ã‚¨ãƒƒã‚¸ã‚’ä½œæˆï¼ˆå¾ªç’°ãƒ‘ã‚¹ï¼‰
    edges = [
        Edge("q1", RelationType.LEADS_TO, "h1"),
        Edge("h1", RelationType.IS_TESTED_BY, "m1"),
        Edge("m1", RelationType.RESULTS_IN, "d1"),
        Edge("d1", RelationType.LEADS_TO_INSIGHT, "i1"),
        Edge("i1", RelationType.MODIFIES, "h2"),  # å¾ªç’°
    ]
    
    for edge in edges:
        graph.add_edge(edge)
    
    # é€²æ—ã‚’è¨ˆç®—
    progress = graph.calculate_progress("s1")
    print(f"âœ… ã‚µã‚¤ã‚¯ãƒ«å®Œäº†æ•°: {progress['cycles_completed']}")
    print(f"âœ… é€²æ—æ®µéš: {progress['stage']}")
    print(f"âœ… ãƒãƒ¼ãƒ‰ç·æ•°: {progress['total_nodes']}")
    
    return graph


def run_all_tests():
    """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("\n" + "="*60)
    print("ğŸš€ ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("="*60)
    
    try:
        # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        graph = test_basic_graph()
        engine = test_inference_engine(graph)
        adapter = test_adapter()
        orchestrator = test_orchestrator()
        cycle_graph = test_cycle_detection()
        
        print("\n" + "="*60)
        print("âœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("="*60)
        
        print("""
ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:
- ã‚°ãƒ©ãƒ•æ“ä½œ: âœ… æ­£å¸¸å‹•ä½œ
- æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³: âœ… ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ¨è«–ãŒæ©Ÿèƒ½
- ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼: âœ… çŠ¶æ…‹å¤‰æ›ãŒæ­£å¸¸
- ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼: âœ… çµ±åˆå‹•ä½œç¢ºèª
- å¾ªç’°æ¤œå‡º: âœ… ã‚µã‚¤ã‚¯ãƒ«ã‚’æ­£ã—ãæ¤œå‡º

ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ ã¯æœ¬ç•ªç’°å¢ƒã§ã®ä½¿ç”¨æº–å‚™ãŒæ•´ã£ã¦ã„ã¾ã™ï¼
        """)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    required_files = ["ontology.yaml", "constraints.yaml"]
    missing_files = []
    
    for file in required_files:
        if not Path(file).exists():
            missing_files.append(file)
    
    if missing_files:
        print(f"âš ï¸ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_files}")
        print("ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    success = run_all_tests()
    sys.exit(0 if success else 1)